{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad2444b-2619-4966-a716-c99efd29de22",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58657d6-81c5-4b08-aa99-6bc88e824bfb",
   "metadata": {},
   "source": [
    "### 1) Setup & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f032a7-b0d5-49b1-9539-22e0dcf16581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# INPUT: folder containing files like TL0101_NDVI_EVI_monthly_admn2.csv\n",
    "INPUT_DIR  = Path(r\"C:\\temp\\timor_leste\\ndvi_evi\")\n",
    "OUTPUT_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "PLOTS_DIR  = OUTPUT_DIR / \"plots\"\n",
    "\n",
    "# Category subfolders for plots\n",
    "PLOT_DIR_AUC_NDVI        = PLOTS_DIR / \"auc_ndvi\"\n",
    "PLOT_DIR_AUC_EVI         = PLOTS_DIR / \"auc_evi\"\n",
    "PLOT_DIR_HARV_MEAN_NDVI  = PLOTS_DIR / \"harvest_mean_ndvi\"\n",
    "PLOT_DIR_HARV_MEAN_EVI   = PLOTS_DIR / \"harvest_mean_evi\"\n",
    "\n",
    "# Make dirs\n",
    "for d in [OUTPUT_DIR, PLOTS_DIR, PLOT_DIR_AUC_NDVI, PLOT_DIR_AUC_EVI, PLOT_DIR_HARV_MEAN_NDVI, PLOT_DIR_HARV_MEAN_EVI]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Config\n",
    "BASELINE_YEARS  = [2019, 2020, 2021]\n",
    "ANALYSIS_YEARS  = [2022, 2023, 2024, 2025]\n",
    "HARVEST_MONTHS  = [4, 5, 6, 7]   # Apr–Jul (harvest window)\n",
    "\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_columns\", 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7afda0-fd07-409d-bf36-1a22e42a8829",
   "metadata": {},
   "source": [
    "### 2) Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96768-2a53-44cc-b2c9-562ca491d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "def _read_one_csv(fp: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'date' column in {fp}\")\n",
    "    df[\"date\"]  = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"]  = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"days_in_month\"] = df[\"date\"].dt.days_in_month\n",
    "\n",
    "    # Infer ADM2 from filename if needed\n",
    "    adm2_guess = Path(fp).name.split(\"_\")[0]\n",
    "    if \"ADM2_PCODE\" not in df.columns:\n",
    "        df[\"ADM2_PCODE\"] = adm2_guess\n",
    "    else:\n",
    "        df[\"ADM2_PCODE\"] = df[\"ADM2_PCODE\"].fillna(adm2_guess)\n",
    "\n",
    "    # Cast numerics\n",
    "    for col in [\"mean_NDVI\",\"max_NDVI\",\"mean_EVI\",\"max_EVI\",\n",
    "                \"clear_frac_mean\",\"clear_frac_max\",\"count_images\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def load_monthly_files(input_dir: Path, max_workers: int = 8) -> pd.DataFrame:\n",
    "    files = glob.glob(str(input_dir / \"*.csv\"))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No CSVs found in {input_dir}\")\n",
    "    frames = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = {ex.submit(_read_one_csv, fp): fp for fp in files}\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=\"Loading CSVs\"):\n",
    "            fp = futures[f]\n",
    "            try:\n",
    "                frames.append(f.result())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {fp}: {e}\")\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# ---- analytics helpers ----\n",
    "def annual_auc(df: pd.DataFrame, index_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Time-weighted AUC = sum(index * days) per ADM2/year.\"\"\"\n",
    "    return (\n",
    "        df.groupby([\"ADM2_PCODE\",\"year\"])\n",
    "          .apply(lambda d: np.nansum(d[index_col] * d[\"days_in_month\"]))\n",
    "          .reset_index(name=f\"AUC_{index_col}\")\n",
    "    )\n",
    "\n",
    "def annual_auc_clearweighted(df: pd.DataFrame, index_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Clear-weighted AUC = sum(index * days * clear_frac_mean) per ADM2/year.\"\"\"\n",
    "    if \"clear_frac_mean\" not in df.columns:\n",
    "        return pd.DataFrame(columns=[\"ADM2_PCODE\",\"year\",f\"AUCcw_{index_col}\"])\n",
    "    return (\n",
    "        df.groupby([\"ADM2_PCODE\",\"year\"])\n",
    "          .apply(lambda d: np.nansum(d[index_col] * d[\"days_in_month\"] * d[\"clear_frac_mean\"]))\n",
    "          .reset_index(name=f\"AUCcw_{index_col}\")\n",
    "    )\n",
    "\n",
    "def harvest_means(df: pd.DataFrame, index_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Mean index across Apr–Jul per ADM2/year.\"\"\"\n",
    "    sub = df[df[\"month\"].isin(HARVEST_MONTHS)]\n",
    "    return sub.groupby([\"ADM2_PCODE\",\"year\"])[index_col].mean().reset_index(name=f\"harv_{index_col}\")\n",
    "\n",
    "def slope_per_adm2(df: pd.DataFrame, value_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Simple linear slope per year per ADM2.\"\"\"\n",
    "    rows = []\n",
    "    for adm2, sub in df[[\"ADM2_PCODE\",\"year\",value_col]].dropna().groupby(\"ADM2_PCODE\"):\n",
    "        x = sub[\"year\"].values.astype(float)\n",
    "        y = sub[value_col].values.astype(float)\n",
    "        slope = np.polyfit(x, y, 1)[0] if len(np.unique(x)) >= 2 else np.nan\n",
    "        rows.append({\"ADM2_PCODE\": adm2, f\"slope_{value_col}\": slope})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def plot_metric_by_adm2(df: pd.DataFrame, value_col: str, title: str, out_png: Path, ylim=None):\n",
    "    \"\"\"Multi-ADM2 line plot with optional fixed y-limits.\"\"\"\n",
    "    plt.figure()\n",
    "    for adm2, sub in df.sort_values([\"ADM2_PCODE\",\"year\"]).groupby(\"ADM2_PCODE\"):\n",
    "        plt.plot(sub[\"year\"], sub[value_col], label=adm2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Year\"); plt.ylabel(value_col)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    plt.legend(ncols=2, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "\n",
    "def plot_per_adm2(df: pd.DataFrame, value_col: str, out_dir: Path, ylim=None, title_prefix:str=\"\"):\n",
    "    \"\"\"One PNG per ADM2 with consistent y-limit, saved to out_dir.\"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for adm2, sub in tqdm(df.groupby(\"ADM2_PCODE\"), total=df[\"ADM2_PCODE\"].nunique(), desc=f\"Plots: {value_col}\"):\n",
    "        plt.figure()\n",
    "        plt.plot(sub[\"year\"], sub[value_col])\n",
    "        plt.title(f\"{title_prefix}{adm2}\")\n",
    "        plt.xlabel(\"Year\"); plt.ylabel(value_col)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{adm2}_{value_col}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def padded_limits(series: pd.Series, pad: float = 0.05):\n",
    "    \"\"\"Compute padded [min,max] for AUC-type series; handles NaNs.\"\"\"\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return (0, 1)\n",
    "    lo, hi = s.min(), s.max()\n",
    "    if lo == hi:\n",
    "        # avoid zero-span axis\n",
    "        span = abs(hi) if hi != 0 else 1.0\n",
    "        lo, hi = hi - 0.1*span, hi + 0.1*span\n",
    "    pad_span = (hi - lo) * pad\n",
    "    return (lo - pad_span, hi + pad_span)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f332ce-9472-471d-a4ad-0c93e1e72eac",
   "metadata": {},
   "source": [
    "### 3) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4bb48-0d9c-4469-9ea0-a1308f5cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_monthly_files(INPUT_DIR, max_workers=12)  # tweak workers if you like\n",
    "print(\"Rows:\", len(data), \" | ADM2s:\", data['ADM2_PCODE'].nunique())\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba25a0-8b60-4451-91b9-ce4b54908847",
   "metadata": {},
   "source": [
    "### 4) Build annual metrics (AUCs & harvest-window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec75de0-42bf-4990-b430-f0ff6247e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_ndvi = annual_auc(data, \"mean_NDVI\")\n",
    "auc_evi  = annual_auc(data, \"mean_EVI\")\n",
    "auc_ndvi_cw = annual_auc_clearweighted(data, \"mean_NDVI\")\n",
    "auc_evi_cw  = annual_auc_clearweighted(data, \"mean_EVI\")\n",
    "\n",
    "harv_ndvi = harvest_means(data, \"mean_NDVI\")\n",
    "harv_evi  = harvest_means(data, \"mean_EVI\")\n",
    "\n",
    "metrics = (auc_ndvi.merge(auc_evi, on=[\"ADM2_PCODE\",\"year\"], how=\"outer\")\n",
    "                    .merge(auc_ndvi_cw, on=[\"ADM2_PCODE\",\"year\"], how=\"left\")\n",
    "                    .merge(auc_evi_cw,  on=[\"ADM2_PCODE\",\"year\"], how=\"left\")\n",
    "                    .merge(harv_ndvi,   on=[\"ADM2_PCODE\",\"year\"], how=\"left\")\n",
    "                    .merge(harv_evi,    on=[\"ADM2_PCODE\",\"year\"], how=\"left\"))\n",
    "metrics.sort_values([\"ADM2_PCODE\",\"year\"]).head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fde3a-bba1-4de2-b993-4c7ae07a5d1b",
   "metadata": {},
   "source": [
    "### 5) Baseline (2019–2021) & anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7584cc2-ba25-4576-8153-7208a99b7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = (\n",
    "    metrics[metrics[\"year\"].isin(BASELINE_YEARS)]\n",
    "    .groupby(\"ADM2_PCODE\")\n",
    "    .agg({\n",
    "        \"AUC_mean_NDVI\":\"mean\", \"AUC_mean_EVI\":\"mean\",\n",
    "        \"harv_mean_NDVI\":\"mean\",\"harv_mean_EVI\":\"mean\",\n",
    "        \"AUCcw_mean_NDVI\":\"mean\",\"AUCcw_mean_EVI\":\"mean\",\n",
    "    })\n",
    "    .rename(columns={\n",
    "        \"AUC_mean_NDVI\":\"base_AUC_NDVI\",\n",
    "        \"AUC_mean_EVI\":\"base_AUC_EVI\",\n",
    "        \"harv_mean_NDVI\":\"base_harv_NDVI\",\n",
    "        \"harv_mean_EVI\":\"base_harv_EVI\",\n",
    "        \"AUCcw_mean_NDVI\":\"base_AUCcw_NDVI\",\n",
    "        \"AUCcw_mean_EVI\":\"base_AUCcw_EVI\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "metrics = metrics.merge(base, on=\"ADM2_PCODE\", how=\"left\")\n",
    "\n",
    "for col, bcol in [\n",
    "    (\"AUC_mean_NDVI\",\"base_AUC_NDVI\"),\n",
    "    (\"AUC_mean_EVI\",\"base_AUC_EVI\"),\n",
    "    (\"harv_mean_NDVI\",\"base_harv_NDVI\"),\n",
    "    (\"harv_mean_EVI\",\"base_harv_EVI\"),\n",
    "    (\"AUCcw_mean_NDVI\",\"base_AUCcw_NDVI\"),\n",
    "    (\"AUCcw_mean_EVI\",\"base_AUCcw_EVI\"),\n",
    "]:\n",
    "    if col in metrics.columns and bcol in metrics.columns:\n",
    "        metrics[f\"{col}_anom\"] = metrics[col] - metrics[bcol]\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            metrics[f\"{col}_anom_pct\"] = np.where(\n",
    "                (metrics[bcol].notna()) & (metrics[bcol].abs() > 0),\n",
    "                (metrics[f\"{col}_anom\"] / metrics[bcol]) * 100.0,\n",
    "                np.nan\n",
    "            )\n",
    "\n",
    "metrics.sort_values([\"ADM2_PCODE\",\"year\"]).head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57de94-a0f6-4ab2-ad5c-b7b24bafa996",
   "metadata": {},
   "source": [
    "### 6) Trends & QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223275d-17d6-4b87-8bd5-26312e112677",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_auc_ndvi = slope_per_adm2(metrics, \"AUC_mean_NDVI\")\n",
    "trend_auc_evi  = slope_per_adm2(metrics, \"AUC_mean_EVI\")\n",
    "trend_hndvi    = slope_per_adm2(metrics, \"harv_mean_NDVI\")\n",
    "trend_hevi     = slope_per_adm2(metrics, \"harv_mean_EVI\")\n",
    "\n",
    "trend = (trend_auc_ndvi.merge(trend_auc_evi, on=\"ADM2_PCODE\", how=\"outer\")\n",
    "                        .merge(trend_hndvi, on=\"ADM2_PCODE\", how=\"outer\")\n",
    "                        .merge(trend_hevi, on=\"ADM2_PCODE\", how=\"outer\"))\n",
    "\n",
    "qa_harv = data[(data[\"month\"].isin(HARVEST_MONTHS)) & (data[\"year\"].isin(ANALYSIS_YEARS))]\n",
    "if \"clear_frac_mean\" in qa_harv.columns:\n",
    "    qa_summary = qa_harv.groupby(\"ADM2_PCODE\")[\"clear_frac_mean\"].mean().reset_index(name=\"avg_clear_frac_harv_2022_2025\")\n",
    "else:\n",
    "    qa_summary = pd.DataFrame({\"ADM2_PCODE\": metrics[\"ADM2_PCODE\"].unique(), \"avg_clear_frac_harv_2022_2025\": np.nan})\n",
    "\n",
    "# Final summary per ADM2 (averages for 2022–2025)\n",
    "summary = (\n",
    "    base.merge(\n",
    "        metrics[metrics[\"year\"].isin(ANALYSIS_YEARS)]\n",
    "        .groupby(\"ADM2_PCODE\")\n",
    "        .agg({\n",
    "            \"AUC_mean_NDVI_anom\":\"mean\",\n",
    "            \"AUC_mean_EVI_anom\":\"mean\",\n",
    "            \"AUC_mean_NDVI_anom_pct\":\"mean\",\n",
    "            \"AUC_mean_EVI_anom_pct\":\"mean\",\n",
    "            \"AUCcw_mean_NDVI_anom\":\"mean\",\n",
    "            \"AUCcw_mean_EVI_anom\":\"mean\",\n",
    "            \"AUCcw_mean_NDVI_anom_pct\":\"mean\",\n",
    "            \"AUCcw_mean_EVI_anom_pct\":\"mean\",\n",
    "            \"harv_mean_NDVI_anom\":\"mean\",\n",
    "            \"harv_mean_EVI_anom\":\"mean\",\n",
    "        })\n",
    "        .rename(columns={\n",
    "            \"AUC_mean_NDVI_anom\":\"avg_AUC_NDVI_anom_2022_2025\",\n",
    "            \"AUC_mean_EVI_anom\":\"avg_AUC_EVI_anom_2022_2025\",\n",
    "            \"AUC_mean_NDVI_anom_pct\":\"avg_AUC_NDVI_anom_pct_2022_2025\",\n",
    "            \"AUC_mean_EVI_anom_pct\":\"avg_AUC_EVI_anom_pct_2022_2025\",\n",
    "            \"AUCcw_mean_NDVI_anom\":\"avg_AUCcw_NDVI_anom_2022_2025\",\n",
    "            \"AUCcw_mean_EVI_anom\":\"avg_AUCcw_EVI_anom_2022_2025\",\n",
    "            \"AUCcw_mean_NDVI_anom_pct\":\"avg_AUCcw_NDVI_anom_pct_2022_2025\",\n",
    "            \"AUCcw_mean_EVI_anom_pct\":\"avg_AUCcw_EVI_anom_pct_2022_2025\",\n",
    "            \"harv_mean_NDVI_anom\":\"avg_harv_NDVI_anom_2022_2025\",\n",
    "            \"harv_mean_EVI_anom\":\"avg_harv_EVI_anom_2022_2025\",\n",
    "        }),\n",
    "        on=\"ADM2_PCODE\", how=\"left\"\n",
    "    )\n",
    "    .merge(trend, on=\"ADM2_PCODE\", how=\"left\")\n",
    "    .merge(qa_summary, on=\"ADM2_PCODE\", how=\"left\")\n",
    ")\n",
    "\n",
    "summary.round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ccbd7-8846-48dc-a11c-b9f4ceda9a4d",
   "metadata": {},
   "source": [
    "### 7) Save CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c915f-5d3e-4d06-91d8-128a74c1c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = OUTPUT_DIR / \"panel_summary_by_ADM2.csv\"\n",
    "metrics_path = OUTPUT_DIR / \"panel_yearly_metrics_long.csv\"\n",
    "qa_path      = OUTPUT_DIR / \"panel_QA.csv\"\n",
    "\n",
    "summary.to_csv(summary_path, index=False)\n",
    "metrics.to_csv(metrics_path, index=False)\n",
    "qa_summary.to_csv(qa_path, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", summary_path)\n",
    "print(\"  \", metrics_path)\n",
    "print(\"  \", qa_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792b8c8-86d0-42a0-b2dc-295e40aed157",
   "metadata": {},
   "source": [
    "### 8) Aggregate plots (PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904534d8-7343-4f28-98e8-181ac7b83155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Determine consistent y-limits ----\n",
    "# AUC ranges come from data; harvest means fixed to [0,1]\n",
    "auc_ndvi_ylim = padded_limits(auc_ndvi[\"AUC_mean_NDVI\"], pad=0.08)\n",
    "auc_evi_ylim  = padded_limits(auc_evi[\"AUC_mean_EVI\"],   pad=0.08)\n",
    "harv_ndvi_ylim = (0, 1)\n",
    "harv_evi_ylim  = (0, 1)\n",
    "\n",
    "# ---- Aggregate multi-ADM2 charts (one per metric) ----\n",
    "plot_metric_by_adm2(auc_ndvi, \"AUC_mean_NDVI\",\n",
    "                    \"Annual AUC (mean NDVI) by ADM2\",\n",
    "                    PLOT_DIR_AUC_NDVI / \"overview_auc_ndvi.png\",\n",
    "                    ylim=auc_ndvi_ylim)\n",
    "\n",
    "plot_metric_by_adm2(auc_evi,  \"AUC_mean_EVI\",\n",
    "                    \"Annual AUC (mean EVI) by ADM2\",\n",
    "                    PLOT_DIR_AUC_EVI / \"overview_auc_evi.png\",\n",
    "                    ylim=auc_evi_ylim)\n",
    "\n",
    "plot_metric_by_adm2(harv_ndvi, \"harv_mean_NDVI\",\n",
    "                    \"Harvest-window Mean NDVI (Apr–Jul) by ADM2\",\n",
    "                    PLOT_DIR_HARV_MEAN_NDVI / \"overview_harvest_mean_ndvi.png\",\n",
    "                    ylim=harv_ndvi_ylim)\n",
    "\n",
    "plot_metric_by_adm2(harv_evi,  \"harv_mean_EVI\",\n",
    "                    \"Harvest-window Mean EVI (Apr–Jul) by ADM2\",\n",
    "                    PLOT_DIR_HARV_MEAN_EVI / \"overview_harvest_mean_evi.png\",\n",
    "                    ylim=harv_evi_ylim)\n",
    "\n",
    "print(\"Saved aggregate plots to:\")\n",
    "print(\" -\", PLOT_DIR_AUC_NDVI / \"overview_auc_ndvi.png\")\n",
    "print(\" -\", PLOT_DIR_AUC_EVI / \"overview_auc_evi.png\")\n",
    "print(\" -\", PLOT_DIR_HARV_MEAN_NDVI / \"overview_harvest_mean_ndvi.png\")\n",
    "print(\" -\", PLOT_DIR_HARV_MEAN_EVI / \"overview_harvest_mean_evi.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22a273-7b1e-4a14-858d-3100f9136a31",
   "metadata": {},
   "source": [
    "### 9) Per-ADM2 plots (optional, one PNG per ADM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e3630-010c-4f99-bfde-4e53a01982e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same y-limits computed above for consistency across all ADM2 plots\n",
    "plot_per_adm2(auc_ndvi, \"AUC_mean_NDVI\",\n",
    "              out_dir=PLOT_DIR_AUC_NDVI,\n",
    "              ylim=auc_ndvi_ylim,\n",
    "              title_prefix=\"AUC (NDVI) — \")\n",
    "\n",
    "plot_per_adm2(auc_evi,  \"AUC_mean_EVI\",\n",
    "              out_dir=PLOT_DIR_AUC_EVI,\n",
    "              ylim=auc_evi_ylim,\n",
    "              title_prefix=\"AUC (EVI) — \")\n",
    "\n",
    "plot_per_adm2(harv_ndvi, \"harv_mean_NDVI\",\n",
    "              out_dir=PLOT_DIR_HARV_MEAN_NDVI,\n",
    "              ylim=harv_ndvi_ylim,\n",
    "              title_prefix=\"Harvest mean NDVI (Apr–Jul) — \")\n",
    "\n",
    "plot_per_adm2(harv_evi,  \"harv_mean_EVI\",\n",
    "              out_dir=PLOT_DIR_HARV_MEAN_EVI,\n",
    "              ylim=harv_evi_ylim,\n",
    "              title_prefix=\"Harvest mean EVI (Apr–Jul) — \")\n",
    "\n",
    "print(\"Saved per-ADM2 plots in:\")\n",
    "print(\" -\", PLOT_DIR_AUC_NDVI)\n",
    "print(\" -\", PLOT_DIR_AUC_EVI)\n",
    "print(\" -\", PLOT_DIR_HARV_MEAN_NDVI)\n",
    "print(\" -\", PLOT_DIR_HARV_MEAN_EVI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af66b65-d098-480d-88ae-8b2098d76854",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504934a-616c-463d-a62e-74c8ffec79b5",
   "metadata": {},
   "source": [
    "### 1) Imports, paths, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10f2fa26-a009-4d49-bf89-5d7ecfb6b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Paths ----\n",
    "OUT_DIR    = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "SUMMARY_CSV = OUT_DIR / \"panel_summary_by_ADM2.csv\"\n",
    "METRICS_CSV = OUT_DIR / \"panel_yearly_metrics_long.csv\"\n",
    "\n",
    "# ---- Helper: winsorized z-score (robust to outliers/scale) ----\n",
    "def zscore_winsor(s: pd.Series, p: float = 0.05) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if s.notna().sum() < 2:\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    lo, hi = s.quantile([p, 1 - p])\n",
    "    s_clip = s.clip(lo, hi)\n",
    "    std = s_clip.std(ddof=0)\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    return (s_clip - s_clip.mean()) / std\n",
    "\n",
    "# Percentile rank (0–100)\n",
    "def pct_rank(s: pd.Series) -> pd.Series:\n",
    "    return 100 * s.rank(pct=True, method=\"average\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b1d39-af04-4203-a728-cf8a35819cb8",
   "metadata": {},
   "source": [
    "### 2) Load data & define score recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a53677c-b196-41d1-82e6-35bd50a7c50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM2_PCODE</th>\n",
       "      <th>base_AUC_NDVI</th>\n",
       "      <th>base_AUC_EVI</th>\n",
       "      <th>base_harv_NDVI</th>\n",
       "      <th>base_harv_EVI</th>\n",
       "      <th>base_AUCcw_NDVI</th>\n",
       "      <th>base_AUCcw_EVI</th>\n",
       "      <th>avg_AUC_NDVI_anom_2022_2025</th>\n",
       "      <th>avg_AUC_EVI_anom_2022_2025</th>\n",
       "      <th>avg_AUC_NDVI_anom_pct_2022_2025</th>\n",
       "      <th>avg_AUC_EVI_anom_pct_2022_2025</th>\n",
       "      <th>avg_AUCcw_NDVI_anom_2022_2025</th>\n",
       "      <th>avg_AUCcw_EVI_anom_2022_2025</th>\n",
       "      <th>avg_AUCcw_NDVI_anom_pct_2022_2025</th>\n",
       "      <th>avg_AUCcw_EVI_anom_pct_2022_2025</th>\n",
       "      <th>avg_harv_NDVI_anom_2022_2025</th>\n",
       "      <th>avg_harv_EVI_anom_2022_2025</th>\n",
       "      <th>slope_AUC_mean_NDVI</th>\n",
       "      <th>slope_AUC_mean_EVI</th>\n",
       "      <th>slope_harv_mean_NDVI</th>\n",
       "      <th>slope_harv_mean_EVI</th>\n",
       "      <th>avg_clear_frac_harv_2022_2025</th>\n",
       "      <th>LevelScore</th>\n",
       "      <th>MomentumScore</th>\n",
       "      <th>CombinedScore</th>\n",
       "      <th>ClearWeight</th>\n",
       "      <th>WeightedCombined</th>\n",
       "      <th>Rank_Combined</th>\n",
       "      <th>Rank_WeightedCombined</th>\n",
       "      <th>Pct_WeightedCombined</th>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>Rank_Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TL0502</td>\n",
       "      <td>188.831535</td>\n",
       "      <td>147.111393</td>\n",
       "      <td>0.608915</td>\n",
       "      <td>0.438251</td>\n",
       "      <td>75.164641</td>\n",
       "      <td>55.632066</td>\n",
       "      <td>-50.140060</td>\n",
       "      <td>21.175801</td>\n",
       "      <td>-26.552800</td>\n",
       "      <td>14.394399</td>\n",
       "      <td>-21.252343</td>\n",
       "      <td>8.470163</td>\n",
       "      <td>-28.274390</td>\n",
       "      <td>15.225326</td>\n",
       "      <td>-0.171435</td>\n",
       "      <td>0.079708</td>\n",
       "      <td>-14.168191</td>\n",
       "      <td>0.629696</td>\n",
       "      <td>-0.039864</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>0.355820</td>\n",
       "      <td>1.731120</td>\n",
       "      <td>5.938494</td>\n",
       "      <td>3.834807</td>\n",
       "      <td>0.677910</td>\n",
       "      <td>2.599653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TL0504</td>\n",
       "      <td>156.088485</td>\n",
       "      <td>106.889317</td>\n",
       "      <td>0.538001</td>\n",
       "      <td>0.356107</td>\n",
       "      <td>89.524075</td>\n",
       "      <td>60.307198</td>\n",
       "      <td>-35.863156</td>\n",
       "      <td>27.882084</td>\n",
       "      <td>-22.976170</td>\n",
       "      <td>26.085005</td>\n",
       "      <td>-35.042046</td>\n",
       "      <td>-0.033016</td>\n",
       "      <td>-39.142595</td>\n",
       "      <td>-0.054747</td>\n",
       "      <td>-0.160017</td>\n",
       "      <td>0.071314</td>\n",
       "      <td>-10.017682</td>\n",
       "      <td>4.235942</td>\n",
       "      <td>-0.031745</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>0.356653</td>\n",
       "      <td>-3.027391</td>\n",
       "      <td>9.410308</td>\n",
       "      <td>3.191458</td>\n",
       "      <td>0.678326</td>\n",
       "      <td>2.164850</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.4375</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TL0406</td>\n",
       "      <td>197.583698</td>\n",
       "      <td>142.920251</td>\n",
       "      <td>0.652201</td>\n",
       "      <td>0.448079</td>\n",
       "      <td>89.531654</td>\n",
       "      <td>62.084177</td>\n",
       "      <td>-58.117219</td>\n",
       "      <td>18.753013</td>\n",
       "      <td>-29.413975</td>\n",
       "      <td>13.121313</td>\n",
       "      <td>-38.436581</td>\n",
       "      <td>-4.207690</td>\n",
       "      <td>-42.930717</td>\n",
       "      <td>-6.777395</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>0.051761</td>\n",
       "      <td>-14.711089</td>\n",
       "      <td>2.002862</td>\n",
       "      <td>-0.045231</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.371580</td>\n",
       "      <td>2.246525</td>\n",
       "      <td>3.632425</td>\n",
       "      <td>2.939475</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>2.015863</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.8750</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TL0503</td>\n",
       "      <td>213.596804</td>\n",
       "      <td>164.235661</td>\n",
       "      <td>0.689259</td>\n",
       "      <td>0.502722</td>\n",
       "      <td>82.835962</td>\n",
       "      <td>61.715714</td>\n",
       "      <td>-62.332535</td>\n",
       "      <td>21.326175</td>\n",
       "      <td>-29.182335</td>\n",
       "      <td>12.985106</td>\n",
       "      <td>-29.103809</td>\n",
       "      <td>2.334372</td>\n",
       "      <td>-35.134268</td>\n",
       "      <td>3.782459</td>\n",
       "      <td>-0.230600</td>\n",
       "      <td>0.050243</td>\n",
       "      <td>-15.874057</td>\n",
       "      <td>1.640322</td>\n",
       "      <td>-0.050428</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.329105</td>\n",
       "      <td>4.017608</td>\n",
       "      <td>1.669187</td>\n",
       "      <td>2.843397</td>\n",
       "      <td>0.664552</td>\n",
       "      <td>1.889587</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.3125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TL0704</td>\n",
       "      <td>182.539795</td>\n",
       "      <td>130.724707</td>\n",
       "      <td>0.586130</td>\n",
       "      <td>0.394599</td>\n",
       "      <td>93.474107</td>\n",
       "      <td>63.295604</td>\n",
       "      <td>-56.123998</td>\n",
       "      <td>14.847030</td>\n",
       "      <td>-30.746171</td>\n",
       "      <td>11.357478</td>\n",
       "      <td>-39.629520</td>\n",
       "      <td>-3.753658</td>\n",
       "      <td>-42.396254</td>\n",
       "      <td>-5.930361</td>\n",
       "      <td>-0.179190</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>-14.162227</td>\n",
       "      <td>1.438539</td>\n",
       "      <td>-0.039063</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.523266</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>4.400470</td>\n",
       "      <td>2.213785</td>\n",
       "      <td>0.761633</td>\n",
       "      <td>1.686093</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93.7500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TL0303</td>\n",
       "      <td>186.998342</td>\n",
       "      <td>137.488787</td>\n",
       "      <td>0.605013</td>\n",
       "      <td>0.423670</td>\n",
       "      <td>69.426030</td>\n",
       "      <td>49.377727</td>\n",
       "      <td>-59.509057</td>\n",
       "      <td>13.998265</td>\n",
       "      <td>-31.823307</td>\n",
       "      <td>10.181387</td>\n",
       "      <td>-30.564281</td>\n",
       "      <td>-4.418453</td>\n",
       "      <td>-44.024238</td>\n",
       "      <td>-8.948271</td>\n",
       "      <td>-0.196850</td>\n",
       "      <td>0.055888</td>\n",
       "      <td>-13.679965</td>\n",
       "      <td>1.925130</td>\n",
       "      <td>-0.040172</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.326737</td>\n",
       "      <td>0.972752</td>\n",
       "      <td>3.999630</td>\n",
       "      <td>2.486191</td>\n",
       "      <td>0.663368</td>\n",
       "      <td>1.649260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.1875</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TL0501</td>\n",
       "      <td>194.115370</td>\n",
       "      <td>144.460657</td>\n",
       "      <td>0.647162</td>\n",
       "      <td>0.448756</td>\n",
       "      <td>77.078580</td>\n",
       "      <td>54.275239</td>\n",
       "      <td>-57.842749</td>\n",
       "      <td>16.372762</td>\n",
       "      <td>-29.798129</td>\n",
       "      <td>11.333717</td>\n",
       "      <td>-28.584941</td>\n",
       "      <td>0.775897</td>\n",
       "      <td>-37.085453</td>\n",
       "      <td>1.429560</td>\n",
       "      <td>-0.215092</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>-14.539363</td>\n",
       "      <td>1.397291</td>\n",
       "      <td>-0.045638</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.364451</td>\n",
       "      <td>2.161002</td>\n",
       "      <td>2.570767</td>\n",
       "      <td>2.365885</td>\n",
       "      <td>0.682226</td>\n",
       "      <td>1.614067</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90.6250</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TL0204</td>\n",
       "      <td>221.298780</td>\n",
       "      <td>158.140954</td>\n",
       "      <td>0.697764</td>\n",
       "      <td>0.456688</td>\n",
       "      <td>92.712415</td>\n",
       "      <td>61.172135</td>\n",
       "      <td>-70.222484</td>\n",
       "      <td>19.889994</td>\n",
       "      <td>-31.731980</td>\n",
       "      <td>12.577383</td>\n",
       "      <td>-43.363574</td>\n",
       "      <td>-7.819159</td>\n",
       "      <td>-46.772133</td>\n",
       "      <td>-12.782223</td>\n",
       "      <td>-0.226138</td>\n",
       "      <td>0.064144</td>\n",
       "      <td>-18.742742</td>\n",
       "      <td>0.253305</td>\n",
       "      <td>-0.048114</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>0.410948</td>\n",
       "      <td>4.188662</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>2.256446</td>\n",
       "      <td>0.705474</td>\n",
       "      <td>1.591864</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.0625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TL1004</td>\n",
       "      <td>200.875094</td>\n",
       "      <td>135.754727</td>\n",
       "      <td>0.657307</td>\n",
       "      <td>0.430141</td>\n",
       "      <td>83.233735</td>\n",
       "      <td>54.702727</td>\n",
       "      <td>-63.070974</td>\n",
       "      <td>19.906707</td>\n",
       "      <td>-31.398105</td>\n",
       "      <td>14.663731</td>\n",
       "      <td>-39.193621</td>\n",
       "      <td>-6.296505</td>\n",
       "      <td>-47.088625</td>\n",
       "      <td>-11.510403</td>\n",
       "      <td>-0.226356</td>\n",
       "      <td>0.050689</td>\n",
       "      <td>-15.710231</td>\n",
       "      <td>2.439745</td>\n",
       "      <td>-0.047858</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>1.860956</td>\n",
       "      <td>2.755068</td>\n",
       "      <td>2.308012</td>\n",
       "      <td>0.646479</td>\n",
       "      <td>1.492081</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.5000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TL0601</td>\n",
       "      <td>221.573400</td>\n",
       "      <td>162.374228</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.450006</td>\n",
       "      <td>96.252305</td>\n",
       "      <td>67.494913</td>\n",
       "      <td>-73.716272</td>\n",
       "      <td>10.234357</td>\n",
       "      <td>-33.269459</td>\n",
       "      <td>6.302944</td>\n",
       "      <td>-38.896382</td>\n",
       "      <td>-2.625866</td>\n",
       "      <td>-40.410857</td>\n",
       "      <td>-3.890465</td>\n",
       "      <td>-0.204727</td>\n",
       "      <td>0.074739</td>\n",
       "      <td>-17.945063</td>\n",
       "      <td>0.341517</td>\n",
       "      <td>-0.040844</td>\n",
       "      <td>0.019153</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>4.067579</td>\n",
       "      <td>-0.035504</td>\n",
       "      <td>2.016037</td>\n",
       "      <td>0.721720</td>\n",
       "      <td>1.455015</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.9375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADM2_PCODE  base_AUC_NDVI  base_AUC_EVI  base_harv_NDVI  base_harv_EVI  base_AUCcw_NDVI  base_AUCcw_EVI  avg_AUC_NDVI_anom_2022_2025  \\\n",
       "0     TL0502     188.831535    147.111393        0.608915       0.438251        75.164641       55.632066                   -50.140060   \n",
       "1     TL0504     156.088485    106.889317        0.538001       0.356107        89.524075       60.307198                   -35.863156   \n",
       "2     TL0406     197.583698    142.920251        0.652201       0.448079        89.531654       62.084177                   -58.117219   \n",
       "3     TL0503     213.596804    164.235661        0.689259       0.502722        82.835962       61.715714                   -62.332535   \n",
       "4     TL0704     182.539795    130.724707        0.586130       0.394599        93.474107       63.295604                   -56.123998   \n",
       "5     TL0303     186.998342    137.488787        0.605013       0.423670        69.426030       49.377727                   -59.509057   \n",
       "6     TL0501     194.115370    144.460657        0.647162       0.448756        77.078580       54.275239                   -57.842749   \n",
       "7     TL0204     221.298780    158.140954        0.697764       0.456688        92.712415       61.172135                   -70.222484   \n",
       "8     TL1004     200.875094    135.754727        0.657307       0.430141        83.233735       54.702727                   -63.070974   \n",
       "9     TL0601     221.573400    162.374228        0.672414       0.450006        96.252305       67.494913                   -73.716272   \n",
       "\n",
       "   avg_AUC_EVI_anom_2022_2025  avg_AUC_NDVI_anom_pct_2022_2025  avg_AUC_EVI_anom_pct_2022_2025  avg_AUCcw_NDVI_anom_2022_2025  \\\n",
       "0                   21.175801                       -26.552800                       14.394399                     -21.252343   \n",
       "1                   27.882084                       -22.976170                       26.085005                     -35.042046   \n",
       "2                   18.753013                       -29.413975                       13.121313                     -38.436581   \n",
       "3                   21.326175                       -29.182335                       12.985106                     -29.103809   \n",
       "4                   14.847030                       -30.746171                       11.357478                     -39.629520   \n",
       "5                   13.998265                       -31.823307                       10.181387                     -30.564281   \n",
       "6                   16.372762                       -29.798129                       11.333717                     -28.584941   \n",
       "7                   19.889994                       -31.731980                       12.577383                     -43.363574   \n",
       "8                   19.906707                       -31.398105                       14.663731                     -39.193621   \n",
       "9                   10.234357                       -33.269459                        6.302944                     -38.896382   \n",
       "\n",
       "   avg_AUCcw_EVI_anom_2022_2025  avg_AUCcw_NDVI_anom_pct_2022_2025  avg_AUCcw_EVI_anom_pct_2022_2025  avg_harv_NDVI_anom_2022_2025  \\\n",
       "0                      8.470163                         -28.274390                         15.225326                     -0.171435   \n",
       "1                     -0.033016                         -39.142595                         -0.054747                     -0.160017   \n",
       "2                     -4.207690                         -42.930717                         -6.777395                     -0.213177   \n",
       "3                      2.334372                         -35.134268                          3.782459                     -0.230600   \n",
       "4                     -3.753658                         -42.396254                         -5.930361                     -0.179190   \n",
       "5                     -4.418453                         -44.024238                         -8.948271                     -0.196850   \n",
       "6                      0.775897                         -37.085453                          1.429560                     -0.215092   \n",
       "7                     -7.819159                         -46.772133                        -12.782223                     -0.226138   \n",
       "8                     -6.296505                         -47.088625                        -11.510403                     -0.226356   \n",
       "9                     -2.625866                         -40.410857                         -3.890465                     -0.204727   \n",
       "\n",
       "   avg_harv_EVI_anom_2022_2025  slope_AUC_mean_NDVI  slope_AUC_mean_EVI  slope_harv_mean_NDVI  slope_harv_mean_EVI  \\\n",
       "0                     0.079708           -14.168191            0.629696             -0.039864             0.015738   \n",
       "1                     0.071314           -10.017682            4.235942             -0.031745             0.019172   \n",
       "2                     0.051761           -14.711089            2.002862             -0.045231             0.012722   \n",
       "3                     0.050243           -15.874057            1.640322             -0.050428             0.009559   \n",
       "4                     0.059322           -14.162227            1.438539             -0.039063             0.013115   \n",
       "5                     0.055888           -13.679965            1.925130             -0.040172             0.014268   \n",
       "6                     0.046700           -14.539363            1.397291             -0.045638             0.010910   \n",
       "7                     0.064144           -18.742742            0.253305             -0.048114             0.013850   \n",
       "8                     0.050689           -15.710231            2.439745             -0.047858             0.012788   \n",
       "9                     0.074739           -17.945063            0.341517             -0.040844             0.019153   \n",
       "\n",
       "   avg_clear_frac_harv_2022_2025  LevelScore  MomentumScore  CombinedScore  ClearWeight  WeightedCombined  Rank_Combined  \\\n",
       "0                       0.355820    1.731120       5.938494       3.834807     0.677910          2.599653            1.0   \n",
       "1                       0.356653   -3.027391       9.410308       3.191458     0.678326          2.164850            2.0   \n",
       "2                       0.371580    2.246525       3.632425       2.939475     0.685790          2.015863            3.0   \n",
       "3                       0.329105    4.017608       1.669187       2.843397     0.664552          1.889587            4.0   \n",
       "4                       0.523266    0.027101       4.400470       2.213785     0.761633          1.686093            9.0   \n",
       "5                       0.326737    0.972752       3.999630       2.486191     0.663368          1.649260            5.0   \n",
       "6                       0.364451    2.161002       2.570767       2.365885     0.682226          1.614067            6.0   \n",
       "7                       0.410948    4.188662       0.324229       2.256446     0.705474          1.591864            8.0   \n",
       "8                       0.292958    1.860956       2.755068       2.308012     0.646479          1.492081            7.0   \n",
       "9                       0.443441    4.067579      -0.035504       2.016037     0.721720          1.455015           12.0   \n",
       "\n",
       "   Rank_WeightedCombined  Pct_WeightedCombined  Rank_Level  Rank_Momentum  \n",
       "0                    1.0              100.0000        26.0            4.0  \n",
       "1                    2.0               98.4375        52.0            1.0  \n",
       "2                    3.0               96.8750        17.0           11.0  \n",
       "3                    4.0               95.3125         3.0           20.0  \n",
       "4                    5.0               93.7500        35.0            9.0  \n",
       "5                    6.0               92.1875        31.0           10.0  \n",
       "6                    7.0               90.6250        19.0           14.0  \n",
       "7                    8.0               89.0625         1.0           29.0  \n",
       "8                    9.0               87.5000        24.0           13.0  \n",
       "9                   10.0               85.9375         2.0           34.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your summary (ADM2-level) and yearly metrics (long)\n",
    "summary = pd.read_csv(SUMMARY_CSV)\n",
    "metrics = pd.read_csv(METRICS_CSV)\n",
    "\n",
    "# If any columns are missing (older runs), create placeholders\n",
    "for col in [\n",
    "    \"base_AUC_NDVI\", \"base_AUC_EVI\", \"base_harv_NDVI\", \"base_harv_EVI\",\n",
    "    \"avg_AUC_NDVI_anom_2022_2025\", \"avg_AUC_EVI_anom_2022_2025\",\n",
    "    \"avg_harv_NDVI_anom_2022_2025\", \"avg_harv_EVI_anom_2022_2025\",\n",
    "    \"slope_AUC_mean_NDVI\", \"slope_AUC_mean_EVI\",\n",
    "    \"slope_harv_mean_NDVI\", \"slope_harv_mean_EVI\",\n",
    "    \"avg_clear_frac_harv_2022_2025\"\n",
    "]:\n",
    "    if col not in summary.columns:\n",
    "        summary[col] = np.nan\n",
    "\n",
    "# ---- Scoring weights (tweak as desired) ----\n",
    "W_LEVEL = {\n",
    "    # historical level: emphasize long-season productivity (AUC), include harvest means\n",
    "    \"base_AUC_NDVI\": 1.0,\n",
    "    \"base_AUC_EVI\":  1.0,\n",
    "    \"base_harv_NDVI\": 0.5,\n",
    "    \"base_harv_EVI\":  0.5,\n",
    "}\n",
    "W_MOMENTUM = {\n",
    "    # anomalies 2022–2025 (bigger is better)\n",
    "    \"avg_AUC_NDVI_anom_2022_2025\": 1.0,\n",
    "    \"avg_AUC_EVI_anom_2022_2025\":  1.0,\n",
    "    \"avg_harv_NDVI_anom_2022_2025\": 0.5,\n",
    "    \"avg_harv_EVI_anom_2022_2025\":  0.5,\n",
    "    # slope (per year): emphasize AUC slopes, include harvest slopes\n",
    "    \"slope_AUC_mean_NDVI\": 0.75,\n",
    "    \"slope_AUC_mean_EVI\":  0.75,\n",
    "    \"slope_harv_mean_NDVI\": 0.5,\n",
    "    \"slope_harv_mean_EVI\":  0.5,\n",
    "}\n",
    "\n",
    "ALPHA_LEVEL = 0.5   # weight for Level vs Momentum in combined score\n",
    "ALPHA_MOM   = 0.5\n",
    "\n",
    "# QA weighting: downweight low clear fraction (range ~0.5..1)\n",
    "# If you prefer no QA weighting, set BETA_QA=0\n",
    "BETA_QA = 1.0\n",
    "def qa_weight(cf):\n",
    "    cf = pd.to_numeric(cf, errors=\"coerce\").fillna(1.0)\n",
    "    return 0.5 + 0.5 * cf  # 0.5 (low certainty) .. 1.0 (high clarity)\n",
    "\n",
    "# ---- Build standardized components ----\n",
    "lvl_terms = []\n",
    "for col, w in W_LEVEL.items():\n",
    "    z = zscore_winsor(summary[col])\n",
    "    lvl_terms.append(w * z)\n",
    "summary[\"LevelScore\"] = np.sum(lvl_terms, axis=0)\n",
    "\n",
    "mom_terms = []\n",
    "for col, w in W_MOMENTUM.items():\n",
    "    z = zscore_winsor(summary[col])\n",
    "    mom_terms.append(w * z)\n",
    "summary[\"MomentumScore\"] = np.sum(mom_terms, axis=0)\n",
    "\n",
    "# Combined & QA-weighted scores\n",
    "summary[\"CombinedScore\"] = ALPHA_LEVEL * summary[\"LevelScore\"] + ALPHA_MOM * summary[\"MomentumScore\"]\n",
    "summary[\"ClearWeight\"]   = qa_weight(summary[\"avg_clear_frac_harv_2022_2025\"])\n",
    "summary[\"WeightedCombined\"] = summary[\"CombinedScore\"] * (summary[\"ClearWeight\"] ** BETA_QA)\n",
    "\n",
    "# Ranks & percentiles (higher score = better rank)\n",
    "summary[\"Rank_Combined\"] = summary[\"CombinedScore\"].rank(ascending=False, method=\"min\")\n",
    "summary[\"Rank_WeightedCombined\"] = summary[\"WeightedCombined\"].rank(ascending=False, method=\"min\")\n",
    "summary[\"Pct_WeightedCombined\"] = pct_rank(summary[\"WeightedCombined\"])\n",
    "\n",
    "# Also keep separate ranks for diagnostics\n",
    "summary[\"Rank_Level\"]    = summary[\"LevelScore\"].rank(ascending=False, method=\"min\")\n",
    "summary[\"Rank_Momentum\"] = summary[\"MomentumScore\"].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# Sort for leaderboard\n",
    "leaderboard = summary.sort_values(\"WeightedCombined\", ascending=False).reset_index(drop=True)\n",
    "leaderboard.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae0300-851d-4483-9edc-7807870fb305",
   "metadata": {},
   "source": [
    "### 3) Export overall leaderboard & quick printouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ffe4aaf-fc18-4666-b094-f6eb47d2fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 (QA-weighted combined):\n",
      "ADM2_PCODE  WeightedCombined  Rank_WeightedCombined\n",
      "    TL0502          2.599653                    1.0\n",
      "    TL0504          2.164850                    2.0\n",
      "    TL0406          2.015863                    3.0\n",
      "    TL0503          1.889587                    4.0\n",
      "    TL0704          1.686093                    5.0\n",
      "    TL0303          1.649260                    6.0\n",
      "    TL0501          1.614067                    7.0\n",
      "    TL0204          1.591864                    8.0\n",
      "    TL1004          1.492081                    9.0\n",
      "    TL0601          1.455015                   10.0\n",
      "\n",
      "Bottom 10 (QA-weighted combined):\n",
      "ADM2_PCODE  WeightedCombined  Rank_WeightedCombined\n",
      "    TL0705         -1.860836                   55.0\n",
      "    TL1102         -1.949679                   56.0\n",
      "    TL0606         -2.046326                   57.0\n",
      "    TL0104         -2.254713                   58.0\n",
      "    TL0507         -2.345984                   59.0\n",
      "    TL0404         -2.560919                   60.0\n",
      "    TL0305         -2.569229                   61.0\n",
      "    TL0603         -2.603166                   62.0\n",
      "    TL1303         -2.706574                   63.0\n",
      "    TL1103         -3.174031                   64.0\n",
      "\n",
      "Saved overall ranking to: C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_rank_overall.csv\n"
     ]
    }
   ],
   "source": [
    "out_overall = OUT_DIR / \"adm2_rank_overall.csv\"\n",
    "leaderboard_cols = [\n",
    "    \"ADM2_PCODE\",\n",
    "    \"LevelScore\",\"Rank_Level\",\n",
    "    \"MomentumScore\",\"Rank_Momentum\",\n",
    "    \"CombinedScore\",\"Rank_Combined\",\n",
    "    \"ClearWeight\",\"WeightedCombined\",\"Rank_WeightedCombined\",\"Pct_WeightedCombined\",\n",
    "    # optional context columns:\n",
    "    \"base_AUC_NDVI\",\"base_AUC_EVI\",\"base_harv_NDVI\",\"base_harv_EVI\",\n",
    "    \"avg_AUC_NDVI_anom_2022_2025\",\"avg_AUC_EVI_anom_2022_2025\",\n",
    "    \"avg_harv_NDVI_anom_2022_2025\",\"avg_harv_EVI_anom_2022_2025\",\n",
    "    \"slope_AUC_mean_NDVI\",\"slope_AUC_mean_EVI\",\"slope_harv_mean_NDVI\",\"slope_harv_mean_EVI\",\n",
    "    \"avg_clear_frac_harv_2022_2025\"\n",
    "]\n",
    "leaderboard[leaderboard_cols].to_csv(out_overall, index=False)\n",
    "\n",
    "print(\"Top 10 (QA-weighted combined):\")\n",
    "print(leaderboard[[\"ADM2_PCODE\",\"WeightedCombined\",\"Rank_WeightedCombined\"]].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nBottom 10 (QA-weighted combined):\")\n",
    "print(leaderboard[[\"ADM2_PCODE\",\"WeightedCombined\",\"Rank_WeightedCombined\"]].tail(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nSaved overall ranking to:\", out_overall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9945aa-4afd-4dd0-aa4c-05d519d2950a",
   "metadata": {},
   "source": [
    "### 4) Per-year rankings (2019–2025) from the long “metrics” table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8f47db5-a496-400e-a964-c7594cdbace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-year rankings to: C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_rank_by_year.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM2_PCODE</th>\n",
       "      <th>year</th>\n",
       "      <th>YearScore</th>\n",
       "      <th>YearRank</th>\n",
       "      <th>YearPct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TL0204</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.592785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TL0601</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.237262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TL0203</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.198976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TL0503</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.166826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TL1105</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.678777</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TL0802</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.527873</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TL0101</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.233169</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TL1104</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.212052</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TL0502</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.192207</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TL0405</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.962231</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TL1002</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.890051</td>\n",
       "      <td>11.0</td>\n",
       "      <td>84.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TL0304</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.774528</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADM2_PCODE  year  YearScore  YearRank   YearPct\n",
       "7      TL0204  2019   4.592785       1.0  100.0000\n",
       "27     TL0601  2019   4.237262       2.0   98.4375\n",
       "6      TL0203  2019   4.198976       3.0   96.8750\n",
       "22     TL0503  2019   4.166826       4.0   95.3125\n",
       "53     TL1105  2019   3.678777       5.0   93.7500\n",
       "38     TL0802  2019   3.527873       6.0   92.1875\n",
       "0      TL0101  2019   3.233169       7.0   90.6250\n",
       "52     TL1104  2019   3.212052       8.0   89.0625\n",
       "21     TL0502  2019   3.192207       9.0   87.5000\n",
       "18     TL0405  2019   2.962231      10.0   85.9375\n",
       "46     TL1002  2019   2.890051      11.0   84.3750\n",
       "11     TL0304  2019   2.774528      12.0   82.8125"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure needed columns exist\n",
    "for col in [\"AUC_mean_NDVI\",\"AUC_mean_EVI\",\"harv_mean_NDVI\",\"harv_mean_EVI\",\"year\"]:\n",
    "    if col not in metrics.columns:\n",
    "        raise ValueError(f\"Column '{col}' missing from metrics CSV.\")\n",
    "\n",
    "def per_year_score(df_year: pd.DataFrame) -> pd.Series:\n",
    "    # Standardize per-year across ADM2 so each year is comparable internally\n",
    "    z_auc_ndvi = zscore_winsor(df_year[\"AUC_mean_NDVI\"])\n",
    "    z_auc_evi  = zscore_winsor(df_year[\"AUC_mean_EVI\"])\n",
    "    z_h_ndvi   = zscore_winsor(df_year[\"harv_mean_NDVI\"])\n",
    "    z_h_evi    = zscore_winsor(df_year[\"harv_mean_EVI\"])\n",
    "    # Emphasize AUC, include harvest means\n",
    "    return 1.0*z_auc_ndvi + 1.0*z_auc_evi + 0.5*z_h_ndvi + 0.5*z_h_evi\n",
    "\n",
    "rows = []\n",
    "for yr, dfy in metrics.groupby(\"year\"):\n",
    "    dfy = dfy.copy()\n",
    "    dfy[\"YearScore\"] = per_year_score(dfy)\n",
    "    dfy[\"YearRank\"]  = dfy[\"YearScore\"].rank(ascending=False, method=\"min\")\n",
    "    dfy[\"YearPct\"]   = pct_rank(dfy[\"YearScore\"])\n",
    "    rows.append(dfy[[\"ADM2_PCODE\",\"year\",\"YearScore\",\"YearRank\",\"YearPct\"]])\n",
    "\n",
    "yearly_rank = pd.concat(rows, ignore_index=True).sort_values([\"year\",\"YearRank\"])\n",
    "out_yearly = OUT_DIR / \"adm2_rank_by_year.csv\"\n",
    "yearly_rank.to_csv(out_yearly, index=False)\n",
    "\n",
    "print(\"Saved per-year rankings to:\", out_yearly)\n",
    "yearly_rank.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfdcab-a805-4bcb-b375-68c76187ec78",
   "metadata": {},
   "source": [
    "### 5) Compact report table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a911cea-946e-4d8e-866a-39a23bee332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full-category outputs to:\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_category_rankings.xlsx\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_overall_leaders.csv\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_top_baseline.csv\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_top_improvers.csv\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\adm2_most_stable.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Export full (all-ADM2) category rankings + updated workbook\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Resolve dirs & (re)load if needed ---\n",
    "if 'OUTPUT_DIR' in globals():\n",
    "    OUT_DIR = OUTPUT_DIR\n",
    "else:\n",
    "    OUT_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_CSV = OUT_DIR / \"panel_summary_by_ADM2.csv\"\n",
    "METRICS_CSV = OUT_DIR / \"panel_yearly_metrics_long.csv\"\n",
    "\n",
    "if 'summary' not in globals() or not isinstance(summary, pd.DataFrame):\n",
    "    summary = pd.read_csv(SUMMARY_CSV)\n",
    "if 'metrics' not in globals() or not isinstance(metrics, pd.DataFrame):\n",
    "    metrics = pd.read_csv(METRICS_CSV)\n",
    "\n",
    "# --- Helper for CV & winsor z (small, local versions) ---\n",
    "def _cv(series: pd.Series) -> float:\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if len(s) < 3 or s.mean() == 0:\n",
    "        return np.nan\n",
    "    return float(s.std(ddof=0) / s.mean())\n",
    "\n",
    "def zscore_winsor(s: pd.Series, p: float = 0.05) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if s.notna().sum() < 2:\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    lo, hi = s.quantile([p, 1-p])\n",
    "    s_clip = s.clip(lo, hi)\n",
    "    std = s_clip.std(ddof=0)\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return pd.Series(np.zeros(len(s)), index=s.index)\n",
    "    return (s_clip - s_clip.mean()) / std\n",
    "\n",
    "# --- Build CV table (for stability) if needed ---\n",
    "cv_all = (metrics\n",
    "          .groupby(\"ADM2_PCODE\")\n",
    "          .agg(cv_auc_ndvi=(\"AUC_mean_NDVI\", _cv),\n",
    "               cv_auc_evi =(\"AUC_mean_EVI\",  _cv))\n",
    "          .reset_index())\n",
    "cv_all[\"cv_auc_mean\"] = cv_all[[\"cv_auc_ndvi\",\"cv_auc_evi\"]].mean(axis=1, skipna=True)\n",
    "\n",
    "# --- Full category tables (ALL ADM2s; sorted + ranks) ---\n",
    "overall_leaders_full = (\n",
    "    summary\n",
    "    .assign(OverallRank=lambda d: d[\"WeightedCombined\"].rank(ascending=False, method=\"min\"))\n",
    "    .sort_values([\"WeightedCombined\"], ascending=False)\n",
    "    .loc[:, [\"ADM2_PCODE\",\"OverallRank\",\"WeightedCombined\",\"ClearWeight\",\n",
    "             \"CombinedScore\",\"LevelScore\",\"MomentumScore\"]]\n",
    ")\n",
    "\n",
    "top_baseline_full = (\n",
    "    summary\n",
    "    .assign(BaselineRank=lambda d: d[\"LevelScore\"].rank(ascending=False, method=\"min\"))\n",
    "    .sort_values([\"LevelScore\"], ascending=False)\n",
    "    .loc[:, [\"ADM2_PCODE\",\"BaselineRank\",\"LevelScore\",\n",
    "             \"base_AUC_NDVI\",\"base_AUC_EVI\",\"base_harv_NDVI\",\"base_harv_EVI\"]]\n",
    ")\n",
    "\n",
    "top_improvers_full = (\n",
    "    summary\n",
    "    .assign(ImproverRank=lambda d: d[\"MomentumScore\"].rank(ascending=False, method=\"min\"))\n",
    "    .sort_values([\"MomentumScore\"], ascending=False)\n",
    "    .loc[:, [\"ADM2_PCODE\",\"ImproverRank\",\"MomentumScore\",\n",
    "             \"avg_AUC_NDVI_anom_2022_2025\",\"avg_AUC_EVI_anom_2022_2025\",\n",
    "             \"avg_harv_NDVI_anom_2022_2025\",\"avg_harv_EVI_anom_2022_2025\",\n",
    "             \"slope_AUC_mean_NDVI\",\"slope_AUC_mean_EVI\",\n",
    "             \"slope_harv_mean_NDVI\",\"slope_harv_mean_EVI\"]]\n",
    ")\n",
    "\n",
    "most_stable_full = (\n",
    "    cv_all\n",
    "    .assign(StabilityRank=lambda d: d[\"cv_auc_mean\"].rank(ascending=True, method=\"min\"))\n",
    "    .sort_values([\"cv_auc_mean\",\"cv_auc_ndvi\",\"cv_auc_evi\"], ascending=[True, True, True])\n",
    "    .loc[:, [\"ADM2_PCODE\",\"StabilityRank\",\"cv_auc_mean\",\"cv_auc_ndvi\",\"cv_auc_evi\"]]\n",
    ")\n",
    "\n",
    "# --- Year winners (keep top-5 per year for narrative) ---\n",
    "if 'year_winners' not in globals():\n",
    "    rows = []\n",
    "    for yr, dfy in metrics.groupby(\"year\"):\n",
    "        dfy = dfy.copy()\n",
    "        z_auc_ndvi = zscore_winsor(dfy[\"AUC_mean_NDVI\"])\n",
    "        z_auc_evi  = zscore_winsor(dfy[\"AUC_mean_EVI\"])\n",
    "        z_h_ndvi   = zscore_winsor(dfy[\"harv_mean_NDVI\"])\n",
    "        z_h_evi    = zscore_winsor(dfy[\"harv_mean_EVI\"])\n",
    "        dfy[\"YearScore\"] = 1.0*z_auc_ndvi + 1.0*z_auc_evi + 0.5*z_h_ndvi + 0.5*z_h_evi\n",
    "        dfy[\"YearRank\"]  = dfy[\"YearScore\"].rank(ascending=False, method=\"min\")\n",
    "        rows.append(dfy[[\"ADM2_PCODE\",\"year\",\"YearScore\",\"YearRank\"]])\n",
    "    year_winners = (pd.concat(rows, ignore_index=True)\n",
    "                    .sort_values([\"year\",\"YearRank\"])\n",
    "                    .groupby(\"year\").head(5).reset_index(drop=True))\n",
    "\n",
    "# --- Compact report (same as before; keeps all ADM2s) ---\n",
    "compact_cols = [\n",
    "    \"ADM2_PCODE\",\n",
    "    \"Rank_WeightedCombined\",\"WeightedCombined\",\"ClearWeight\",\n",
    "    \"Rank_Level\",\"LevelScore\",\n",
    "    \"Rank_Momentum\",\"MomentumScore\",\n",
    "    \"base_AUC_NDVI\",\"base_AUC_EVI\",\"base_harv_NDVI\",\"base_harv_EVI\",\n",
    "    \"avg_AUC_NDVI_anom_2022_2025\",\"avg_AUC_EVI_anom_2022_2025\",\n",
    "    \"avg_harv_NDVI_anom_2022_2025\",\"avg_harv_EVI_anom_2022_2025\",\n",
    "    \"slope_AUC_mean_NDVI\",\"slope_AUC_mean_EVI\",\"slope_harv_mean_NDVI\",\"slope_harv_mean_EVI\",\n",
    "]\n",
    "missing_compact = [c for c in compact_cols if c not in summary.columns]\n",
    "if missing_compact:\n",
    "    print(\"Note: some compact-report columns missing; output will include what's available:\", missing_compact)\n",
    "compact = (summary.loc[:, [c for c in compact_cols if c in summary.columns]]\n",
    "           .merge(cv_all, on=\"ADM2_PCODE\", how=\"left\")\n",
    "           .sort_values([\"Rank_WeightedCombined\",\"Rank_Level\"], na_position=\"last\")\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "# --- Save workbook (overwrites existing to include full lists) ---\n",
    "out_xlsx = OUT_DIR / \"adm2_category_rankings.xlsx\"\n",
    "with pd.ExcelWriter(out_xlsx, engine=\"xlsxwriter\") as xw:\n",
    "    overall_leaders_full.to_excel(xw, sheet_name=\"Overall_Leaders\", index=False)\n",
    "    top_baseline_full.to_excel(xw, sheet_name=\"Top_Baseline\", index=False)\n",
    "    top_improvers_full.to_excel(xw, sheet_name=\"Top_Improvers\", index=False)\n",
    "    most_stable_full.to_excel(xw, sheet_name=\"Most_Stable\", index=False)\n",
    "    year_winners.to_excel(xw, sheet_name=\"Year_Winners\", index=False)\n",
    "    compact.to_excel(xw, sheet_name=\"Compact_Report\", index=False)\n",
    "\n",
    "# --- Also save individual CSVs for convenience ---\n",
    "(overall_leaders_full\n",
    " ).to_csv(OUT_DIR / \"adm2_overall_leaders.csv\", index=False)\n",
    "(top_baseline_full\n",
    " ).to_csv(OUT_DIR / \"adm2_top_baseline.csv\", index=False)\n",
    "(top_improvers_full\n",
    " ).to_csv(OUT_DIR / \"adm2_top_improvers.csv\", index=False)\n",
    "(most_stable_full\n",
    " ).to_csv(OUT_DIR / \"adm2_most_stable.csv\", index=False)\n",
    "\n",
    "print(\"Saved full-category outputs to:\")\n",
    "print(\" -\", out_xlsx)\n",
    "print(\" -\", OUT_DIR / \"adm2_overall_leaders.csv\")\n",
    "print(\" -\", OUT_DIR / \"adm2_top_baseline.csv\")\n",
    "print(\" -\", OUT_DIR / \"adm2_top_improvers.csv\")\n",
    "print(\" -\", OUT_DIR / \"adm2_most_stable.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460dc31-b550-449b-9857-cf80a46754a8",
   "metadata": {},
   "source": [
    "## 3) Seasonal graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4980c-ab92-404e-bc13-cf4a19a88379",
   "metadata": {},
   "source": [
    "### Output 'harvest_estimate_consensus'/'harvest_estimate_ndvi'/'harvest_estimate_evi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46628971-8781-4033-aee4-8215450a074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating harvest windows: 100%|██████████████████████████████████████████████████████| 64/64 [00:00<00:00, 70.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved harvest window estimates to: C:\\temp\\timor_leste\\ndvi_evi_outputs\\estimated_harvest_windows.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotated plots: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:45<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated plots saved in:\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\harvest_estimate_consensus\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\harvest_estimate_ndvi\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\harvest_estimate_evi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Estimate harvest window per ADM2 from NDVI/EVI seasonality\n",
    "# ============================================================\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Paths / I/O ----------\n",
    "if 'OUTPUT_DIR' not in globals():\n",
    "    OUTPUT_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "if 'PLOTS_DIR' not in globals():\n",
    "    PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where the monthly CSVs live, if we need to reload:\n",
    "if 'INPUT_DIR' in globals():\n",
    "    MONTHLY_DIR = Path(INPUT_DIR)\n",
    "else:\n",
    "    MONTHLY_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi\")\n",
    "\n",
    "OUT_CSV = OUTPUT_DIR / \"estimated_harvest_windows.csv\"\n",
    "\n",
    "# Optional annotated plots\n",
    "MAKE_ANNOTATED_PLOTS = True\n",
    "PLOT_DIR_CONS   = PLOTS_DIR / \"harvest_estimate_consensus\"\n",
    "PLOT_DIR_NDVI   = PLOTS_DIR / \"harvest_estimate_ndvi\"\n",
    "PLOT_DIR_EVI    = PLOTS_DIR / \"harvest_estimate_evi\"\n",
    "for d in [PLOT_DIR_CONS, PLOT_DIR_NDVI, PLOT_DIR_EVI]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Config ----------\n",
    "BASELINE_YEARS = [2019, 2020, 2021]\n",
    "RECENT_YEARS   = [2022, 2023, 2024, 2025]\n",
    "MIN_CLEAR_FRAC = 0.20   # treat months below this clear fraction as unreliable (masked)\n",
    "Y_LIMIT = (0, 1)\n",
    "\n",
    "# ---------- Load monthly data if needed ----------\n",
    "def _read_one_csv(fp: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'date' column in {fp}\")\n",
    "    df[\"date\"]  = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"]  = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    adm2_guess = Path(fp).name.split(\"_\")[0]\n",
    "    if \"ADM2_PCODE\" not in df.columns:\n",
    "        df[\"ADM2_PCODE\"] = adm2_guess\n",
    "    else:\n",
    "        df[\"ADM2_PCODE\"] = df[\"ADM2_PCODE\"].fillna(adm2_guess)\n",
    "    for col in [\"mean_NDVI\",\"mean_EVI\",\"clear_frac_mean\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _load_monthly_if_needed():\n",
    "    if 'data' in globals():\n",
    "        need = {\"ADM2_PCODE\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"}\n",
    "        if isinstance(data, pd.DataFrame) and need.issubset(data.columns):\n",
    "            return data\n",
    "    files = glob.glob(str(MONTHLY_DIR / \"*.csv\"))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No monthly CSVs found in {MONTHLY_DIR}\")\n",
    "    frames = []\n",
    "    for fp in tqdm(files, desc=\"Loading monthly CSVs\"):\n",
    "        try:\n",
    "            frames.append(_read_one_csv(fp))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fp}: {e}\")\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No valid monthly CSVs loaded.\")\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "data = _load_monthly_if_needed()\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def _cyclic_roll(arr, shift):\n",
    "    shift = shift % len(arr)\n",
    "    if shift == 0: return arr.copy()\n",
    "    return np.concatenate([arr[shift:], arr[:shift]])\n",
    "\n",
    "def _smooth_cyclic(vals, window=3):\n",
    "    \"\"\"Centered moving average with cyclic wrap (expects len=12).\"\"\"\n",
    "    assert len(vals) == 12\n",
    "    x = vals.astype(float).copy()\n",
    "    # simple pad with wrap:\n",
    "    padded = np.r_[x[-(window//2):], x, x[:(window//2)]]\n",
    "    sm = np.convolve(padded, np.ones(window)/window, mode='valid')\n",
    "    return sm  # length 12\n",
    "\n",
    "def _interp_cyclic(months, vals):\n",
    "    \"\"\"Interpolate NaNs on cyclic month axis.\"\"\"\n",
    "    m = np.array(months, dtype=float)\n",
    "    v = vals.astype(float).copy()\n",
    "    isnan = np.isnan(v)\n",
    "    if isnan.all():\n",
    "        return v\n",
    "    # add wrap points (0 with Dec, 13 with Jan) to help endpoints\n",
    "    m_ext = np.r_[0, m, 13]\n",
    "    v_ext = np.r_[v[11], v, v[0]]\n",
    "    good = ~np.isnan(v_ext)\n",
    "    v_interp = np.interp(m_ext, m_ext[good], v_ext[good])\n",
    "    out = v_interp[1:-1]\n",
    "    return out\n",
    "\n",
    "def _estimate_window_from_series(months, vals, clear=None):\n",
    "    \"\"\"\n",
    "    months: 1..12\n",
    "    vals: NDVI/EVI length-12 monthly mean\n",
    "    clear: optional length-12 clear frac (0..1)\n",
    "    Returns dict with start_month, end_month, peak_month, trough_month, range, confidence, method\n",
    "    \"\"\"\n",
    "    months = np.array(months, dtype=int)\n",
    "    x = np.array(vals, dtype=float)\n",
    "\n",
    "    # Mask very low-clear months\n",
    "    if clear is not None:\n",
    "        c = np.array(clear, dtype=float)\n",
    "        x = np.where((~np.isnan(c)) & (c < MIN_CLEAR_FRAC), np.nan, x)\n",
    "\n",
    "    # Fill missing by cyclic interpolation, then smooth\n",
    "    x_filled = _interp_cyclic(months, x)\n",
    "    x_sm = _smooth_cyclic(x_filled, window=3)\n",
    "\n",
    "    # Peak month (tie -> earliest)\n",
    "    peak_idx = int(np.nanargmax(x_sm))\n",
    "    peak_month = int(months[peak_idx])\n",
    "\n",
    "    # Find trough within 6 months after peak (search in rolled space)\n",
    "    rolled = _cyclic_roll(x_sm, peak_idx)  # starts at peak month\n",
    "    # search next 1..6 (avoid the peak itself)\n",
    "    search_slice = rolled[1:7]\n",
    "    trough_rel = int(np.nanargmin(search_slice)) + 1\n",
    "    trough_idx = (peak_idx + trough_rel) % 12\n",
    "    trough_month = int(months[trough_idx])\n",
    "\n",
    "    peak = x_sm[peak_idx]\n",
    "    trough = x_sm[trough_idx]\n",
    "    R = float(peak - trough)\n",
    "\n",
    "    # thresholds\n",
    "    T1 = peak - 0.20 * R  # onset when 20% down from peak\n",
    "    T2 = peak - 0.60 * R  # end when 60% down from peak\n",
    "\n",
    "    # scan forward for onset/end\n",
    "    start_idx = None\n",
    "    end_idx   = None\n",
    "    for k in range(1, 7):  # within 6 months after peak\n",
    "        idx = (peak_idx + k) % 12\n",
    "        if start_idx is None and x_sm[idx] <= T1:\n",
    "            start_idx = idx\n",
    "        if start_idx is not None and x_sm[idx] <= T2:\n",
    "            end_idx = idx\n",
    "            break\n",
    "\n",
    "    # Fallbacks if thresholds not crossed (low contrast etc.)\n",
    "    method = \"percent_of_range\"\n",
    "    if start_idx is None or end_idx is None:\n",
    "        method = \"steepest_decline_fallback\"\n",
    "        diffs = np.r_[np.diff(x_sm), x_sm[0]-x_sm[-1]]  # month-to-month cyclic\n",
    "        # Look for steepest negative slope after the peak\n",
    "        idxs = [(peak_idx + k) % 12 for k in range(1, 7)]\n",
    "        neg_slopes = diffs[idxs]\n",
    "        steep_rel = int(np.nanargmin(neg_slopes)) + 1\n",
    "        center_idx = (peak_idx + steep_rel) % 12\n",
    "        start_idx = start_idx or center_idx\n",
    "        end_idx   = end_idx   or ((center_idx + 1) % 12)\n",
    "\n",
    "    # Normalize ordering across year wrap\n",
    "    # We'll output calendar months (1..12); if end < start, interpret as wrapping across Aug->Oct etc.\n",
    "    start_month = int(months[start_idx])\n",
    "    end_month   = int(months[end_idx])\n",
    "\n",
    "    # Confidence: higher with larger R and more monotonic drop\n",
    "    # monotonic score over the descent window\n",
    "    seq = []\n",
    "    i = start_idx\n",
    "    while True:\n",
    "        j = (i + 1) % 12\n",
    "        seq.append(x_sm[j] - x_sm[i])\n",
    "        i = j\n",
    "        if i == end_idx:\n",
    "            break\n",
    "    monotone = float(np.mean(np.array(seq) < 0)) if seq else 0.0\n",
    "    conf = np.clip((R / 0.35) * (0.5 + 0.5 * monotone), 0, 1)\n",
    "\n",
    "    return dict(\n",
    "        start_month=start_month,\n",
    "        end_month=end_month,\n",
    "        peak_month=peak_month,\n",
    "        trough_month=trough_month,\n",
    "        range_R=round(R, 3),\n",
    "        confidence=round(conf, 3),\n",
    "        method=method\n",
    "    )\n",
    "\n",
    "def _build_recent_climatology(df_adm2, value_col):\n",
    "    \"\"\"Return arrays (months 1..12) of recent-year monthly means (prefers 2022–2025).\"\"\"\n",
    "    months = np.arange(1, 13, dtype=int)\n",
    "    # prefer recent years if present\n",
    "    yrs_present = sorted(df_adm2[\"year\"].unique().tolist())\n",
    "    yrs_recent = [y for y in RECENT_YEARS if y in yrs_present]\n",
    "    if len(yrs_recent) >= 2:\n",
    "        use_years = yrs_recent\n",
    "    else:\n",
    "        use_years = yrs_present  # fallback: all years available\n",
    "    piv = (df_adm2[df_adm2[\"year\"].isin(use_years)]\n",
    "           .pivot_table(index=\"month\", values=value_col, aggfunc=\"mean\"))\n",
    "    series = piv.reindex(months).values.ravel()\n",
    "    return months, series\n",
    "\n",
    "def _build_recent_clear(df_adm2):\n",
    "    months = np.arange(1, 13, dtype=int)\n",
    "    if \"clear_frac_mean\" not in df_adm2.columns:\n",
    "        return months, np.full(12, np.nan)\n",
    "    piv = (df_adm2\n",
    "           .pivot_table(index=\"month\", values=\"clear_frac_mean\", aggfunc=\"mean\"))\n",
    "    series = piv.reindex(months).values.ravel()\n",
    "    return months, series\n",
    "\n",
    "# ---------- Main loop ----------\n",
    "records = []\n",
    "adm2_list = sorted(data[\"ADM2_PCODE\"].dropna().unique().tolist())\n",
    "\n",
    "for adm2 in tqdm(adm2_list, desc=\"Estimating harvest windows\"):\n",
    "    sub = data.loc[data[\"ADM2_PCODE\"] == adm2,\n",
    "                   [\"ADM2_PCODE\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\",\"clear_frac_mean\"]].copy()\n",
    "\n",
    "    m_ndvi, s_ndvi = _build_recent_climatology(sub, \"mean_NDVI\")\n",
    "    m_evi,  s_evi  = _build_recent_climatology(sub, \"mean_EVI\")\n",
    "    m_clr,  s_clr  = _build_recent_clear(sub)\n",
    "\n",
    "    ndvi_est = _estimate_window_from_series(m_ndvi, s_ndvi, clear=s_clr)\n",
    "    evi_est  = _estimate_window_from_series(m_evi,  s_evi,  clear=s_clr)\n",
    "\n",
    "    # Consensus = union (min start, max end). If wrap-around (e.g., start 11, end 2), normalize to May–Aug style if possible.\n",
    "    # Simple union in month numbers:\n",
    "    def _span_to_set(start, end):\n",
    "        if start <= end:\n",
    "            return set(range(start, end+1))\n",
    "        else:\n",
    "            return set(list(range(start, 13)) + list(range(1, end+1)))\n",
    "\n",
    "    ndvi_set = _span_to_set(ndvi_est[\"start_month\"], ndvi_est[\"end_month\"])\n",
    "    evi_set  = _span_to_set(evi_est[\"start_month\"],  evi_est[\"end_month\"])\n",
    "    union    = sorted(list(ndvi_set.union(evi_set)))\n",
    "    if not union:\n",
    "        cons_start, cons_end = ndvi_est[\"start_month\"], ndvi_est[\"end_month\"]\n",
    "        cons_method = \"NDVI_only\"\n",
    "    else:\n",
    "        # merge contiguous wrap-aware\n",
    "        # Heuristic: prefer a window length 2–4 months around mid-year if present\n",
    "        cons_start, cons_end = union[0], union[-1]\n",
    "        cons_method = \"union(NDVI,EVI)\"\n",
    "\n",
    "    records.append({\n",
    "        \"ADM2_PCODE\": adm2,\n",
    "        # NDVI-based\n",
    "        \"ndvi_start_month\": ndvi_est[\"start_month\"],\n",
    "        \"ndvi_end_month\":   ndvi_est[\"end_month\"],\n",
    "        \"ndvi_peak_month\":  ndvi_est[\"peak_month\"],\n",
    "        \"ndvi_trough_month\":ndvi_est[\"trough_month\"],\n",
    "        \"ndvi_range\":       ndvi_est[\"range_R\"],\n",
    "        \"ndvi_confidence\":  ndvi_est[\"confidence\"],\n",
    "        \"ndvi_method\":      ndvi_est[\"method\"],\n",
    "        # EVI-based\n",
    "        \"evi_start_month\":  evi_est[\"start_month\"],\n",
    "        \"evi_end_month\":    evi_est[\"end_month\"],\n",
    "        \"evi_peak_month\":   evi_est[\"peak_month\"],\n",
    "        \"evi_trough_month\": evi_est[\"trough_month\"],\n",
    "        \"evi_range\":        evi_est[\"range_R\"],\n",
    "        \"evi_confidence\":   evi_est[\"confidence\"],\n",
    "        \"evi_method\":       evi_est[\"method\"],\n",
    "        # Consensus\n",
    "        \"consensus_start_month\": cons_start,\n",
    "        \"consensus_end_month\":   cons_end,\n",
    "        \"consensus_method\":      cons_method\n",
    "    })\n",
    "\n",
    "# Save CSV\n",
    "harvest_df = pd.DataFrame.from_records(records)\n",
    "harvest_df.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved harvest window estimates to:\", OUT_CSV)\n",
    "\n",
    "# ---------- Optional: annotated plots ----------\n",
    "def _month_labels():\n",
    "    return [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "\n",
    "def _plot_annotated(adm2, months, series, label, start_m, end_m, out_png):\n",
    "    plt.figure()\n",
    "    plt.plot(months, series, label=label)\n",
    "    # Shade suggested harvest\n",
    "    if start_m <= end_m:\n",
    "        plt.axvspan(start_m-0.5, end_m+0.5, alpha=0.12)\n",
    "    else:\n",
    "        # wrap case\n",
    "        plt.axvspan(0.5, end_m+0.5, alpha=0.12)\n",
    "        plt.axvspan(start_m-0.5, 12.5, alpha=0.12)\n",
    "    # Cosmetics\n",
    "    plt.xticks(months, _month_labels())\n",
    "    plt.ylim(*Y_LIMIT)\n",
    "    plt.xlabel(\"Month\"); plt.ylabel(label)\n",
    "    plt.title(f\"{adm2} — Estimated harvest: {start_m:02d}–{end_m:02d}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "\n",
    "if MAKE_ANNOTATED_PLOTS:\n",
    "    for row in tqdm(harvest_df.itertuples(index=False), total=len(harvest_df), desc=\"Annotated plots\"):\n",
    "        adm2 = row.ADM2_PCODE\n",
    "        sub = data.loc[data[\"ADM2_PCODE\"] == adm2, [\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"]]\n",
    "        m_ndvi, s_ndvi = _build_recent_climatology(sub, \"mean_NDVI\")\n",
    "        m_evi,  s_evi  = _build_recent_climatology(sub, \"mean_EVI\")\n",
    "\n",
    "        # NDVI\n",
    "        _plot_annotated(adm2, m_ndvi, _smooth_cyclic(_interp_cyclic(m_ndvi, s_ndvi), 3),\n",
    "                        \"NDVI\", row.ndvi_start_month, row.ndvi_end_month,\n",
    "                        PLOT_DIR_NDVI / f\"{adm2}_harvest_ndvi.png\")\n",
    "        # EVI\n",
    "        _plot_annotated(adm2, m_evi, _smooth_cyclic(_interp_cyclic(m_evi, s_evi), 3),\n",
    "                        \"EVI\",  row.evi_start_month, row.evi_end_month,\n",
    "                        PLOT_DIR_EVI / f\"{adm2}_harvest_evi.png\")\n",
    "        # Consensus (draw NDVI curve as reference)\n",
    "        _plot_annotated(adm2, m_ndvi, _smooth_cyclic(_interp_cyclic(m_ndvi, s_ndvi), 3),\n",
    "                        \"NDVI (consensus shading)\", row.consensus_start_month, row.consensus_end_month,\n",
    "                        PLOT_DIR_CONS / f\"{adm2}_harvest_consensus.png\")\n",
    "\n",
    "print(\"Annotated plots saved in:\")\n",
    "print(\" -\", PLOT_DIR_CONS)\n",
    "print(\" -\", PLOT_DIR_NDVI)\n",
    "print(\" -\", PLOT_DIR_EVI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2339099-3359-4346-86b7-04eecd566287",
   "metadata": {},
   "source": [
    "### Output 'seasonal_overlay_ndvi_estharvest'/'seasonal_overlay_evi_estharvest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adcd392d-26ec-4790-9100-6e8f5eaba42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recreating overlays with estimated harvest: 100%|██████████████████████████████████████| 64/64 [00:54<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved updated overlays to:\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\seasonal_overlay_ndvi_estharvest\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\seasonal_overlay_evi_estharvest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Recreate seasonal overlays using estimated harvest months (per ADM2)\n",
    "# - NDVI overlay shades NDVI-estimated window\n",
    "# - EVI  overlay shades EVI-estimated window\n",
    "# ======================================================\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Paths ----------\n",
    "if 'OUTPUT_DIR' not in globals():\n",
    "    OUTPUT_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "if 'PLOTS_DIR' not in globals():\n",
    "    PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Monthly CSV location (fallback if `data` is missing)\n",
    "if 'INPUT_DIR' in globals():\n",
    "    MONTHLY_DIR = Path(INPUT_DIR)\n",
    "else:\n",
    "    MONTHLY_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi\")\n",
    "\n",
    "HARVEST_CSV = OUTPUT_DIR / \"estimated_harvest_windows.csv\"\n",
    "if not HARVEST_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Missing {HARVEST_CSV}. Run the harvest-estimation cell first.\")\n",
    "\n",
    "# Output folders (new, so originals remain)\n",
    "NDVI_DIR = PLOTS_DIR / \"seasonal_overlay_ndvi_estharvest\"\n",
    "EVI_DIR  = PLOTS_DIR / \"seasonal_overlay_evi_estharvest\"\n",
    "NDVI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EVI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Config ----------\n",
    "BASELINE_YEARS = [2019, 2020, 2021]\n",
    "Y_LIMIT = (0, 1)  # consistent axis 0..1\n",
    "MONTH_LABELS = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "\n",
    "# ---------- Load monthly data if needed ----------\n",
    "def _read_one_csv(fp: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'date' column in {fp}\")\n",
    "    df[\"date\"]  = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"]  = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    # ADM2 from filename if absent\n",
    "    adm2_guess = Path(fp).name.split(\"_\")[0]\n",
    "    if \"ADM2_PCODE\" not in df.columns:\n",
    "        df[\"ADM2_PCODE\"] = adm2_guess\n",
    "    else:\n",
    "        df[\"ADM2_PCODE\"] = df[\"ADM2_PCODE\"].fillna(adm2_guess)\n",
    "    # Coerce key numeric fields\n",
    "    for col in [\"mean_NDVI\",\"mean_EVI\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _load_monthly_if_needed():\n",
    "    if 'data' in globals():\n",
    "        need = {\"ADM2_PCODE\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"}\n",
    "        if isinstance(data, pd.DataFrame) and need.issubset(data.columns):\n",
    "            return data\n",
    "    files = glob.glob(str(MONTHLY_DIR / \"*.csv\"))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No monthly CSVs found in {MONTHLY_DIR}\")\n",
    "    frames = []\n",
    "    for fp in tqdm(files, desc=\"Loading monthly CSVs\"):\n",
    "        try:\n",
    "            frames.append(_read_one_csv(fp))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fp}: {e}\")\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No valid monthly CSVs loaded.\")\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "data = _load_monthly_if_needed()\n",
    "\n",
    "# ---------- Harvest windows ----------\n",
    "harvest = pd.read_csv(HARVEST_CSV)\n",
    "need_hw = {\"ADM2_PCODE\",\"ndvi_start_month\",\"ndvi_end_month\",\"evi_start_month\",\"evi_end_month\"}\n",
    "if not need_hw.issubset(harvest.columns):\n",
    "    raise ValueError(f\"{HARVEST_CSV} missing columns: {need_hw - set(harvest.columns)}\")\n",
    "\n",
    "# ---------- Plot helper ----------\n",
    "def _shade_window(start_m: int, end_m: int):\n",
    "    \"\"\"Return list of (x0, x1) spans in month-number space for shading, handling wrap-around.\"\"\"\n",
    "    if pd.isna(start_m) or pd.isna(end_m):\n",
    "        return []\n",
    "    start_m = int(start_m); end_m = int(end_m)\n",
    "    if 1 <= start_m <= 12 and 1 <= end_m <= 12:\n",
    "        if start_m <= end_m:\n",
    "            return [(start_m - 0.5, end_m + 0.5)]\n",
    "        else:\n",
    "            return [(0.5, end_m + 0.5), (start_m - 0.5, 12.5)]\n",
    "    return []\n",
    "\n",
    "def _baseline_line(piv, baseline_years):\n",
    "    cols = [y for y in baseline_years if y in piv.columns]\n",
    "    return piv[cols].mean(axis=1) if cols else None\n",
    "\n",
    "def _seasonal_overlay(df_adm2: pd.DataFrame, value_col: str, start_m: int, end_m: int, out_path: Path):\n",
    "    # Pivot: rows=month(1..12), cols=year\n",
    "    months = np.arange(1, 13, dtype=int)\n",
    "    piv = (df_adm2.pivot_table(index=\"month\", columns=\"year\", values=value_col, aggfunc=\"mean\")\n",
    "           .reindex(index=months))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    # lines for each year\n",
    "    for y in sorted([c for c in piv.columns if pd.notna(c)]):\n",
    "        plt.plot(months, piv[y].values, label=str(int(y)))\n",
    "    # baseline\n",
    "    base = _baseline_line(piv, BASELINE_YEARS)\n",
    "    if base is not None:\n",
    "        plt.plot(months, base.values, linewidth=3, label=\"Baseline (2019–2021)\")\n",
    "\n",
    "    # shade harvest\n",
    "    for x0, x1 in _shade_window(start_m, end_m):\n",
    "        plt.axvspan(x0, x1, alpha=0.12)\n",
    "\n",
    "    # cosmetics\n",
    "    plt.xticks(months, MONTH_LABELS)\n",
    "    plt.ylim(*Y_LIMIT)\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(value_col)\n",
    "    adm2 = str(df_adm2[\"ADM2_PCODE\"].iloc[0])\n",
    "    metric = \"NDVI\" if \"NDVI\" in value_col else \"EVI\"\n",
    "    if not (pd.isna(start_m) or pd.isna(end_m)):\n",
    "        title_h = f\" (est. harvest {MONTH_LABELS[start_m-1]}–{MONTH_LABELS[end_m-1]})\"\n",
    "    else:\n",
    "        title_h = \" (no estimate)\"\n",
    "    plt.title(f\"{adm2} — Seasonal overlay ({metric}){title_h}\")\n",
    "    plt.legend(ncols=2, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- Generate overlays with estimated shading ----------\n",
    "adm2_list = sorted(data[\"ADM2_PCODE\"].dropna().unique().tolist())\n",
    "hw_map = harvest.set_index(\"ADM2_PCODE\").to_dict(orient=\"index\")\n",
    "\n",
    "for adm2 in tqdm(adm2_list, desc=\"Recreating overlays with estimated harvest\"):\n",
    "    sub = data.loc[data[\"ADM2_PCODE\"] == adm2, [\"ADM2_PCODE\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"]].copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    # pick windows (NDVI plot uses NDVI window; EVI plot uses EVI window)\n",
    "    hw = hw_map.get(adm2, {})\n",
    "    ndvi_s = hw.get(\"ndvi_start_month\", np.nan); ndvi_e = hw.get(\"ndvi_end_month\", np.nan)\n",
    "    evi_s  = hw.get(\"evi_start_month\",  np.nan); evi_e  = hw.get(\"evi_end_month\",  np.nan)\n",
    "\n",
    "    # NDVI overlay\n",
    "    _seasonal_overlay(\n",
    "        sub[[\"ADM2_PCODE\",\"year\",\"month\",\"mean_NDVI\"]].dropna(subset=[\"mean_NDVI\"]),\n",
    "        \"mean_NDVI\",\n",
    "        ndvi_s, ndvi_e,\n",
    "        NDVI_DIR / f\"{adm2}_seasonal_overlay_ndvi.png\"\n",
    "    )\n",
    "    # EVI overlay\n",
    "    _seasonal_overlay(\n",
    "        sub[[\"ADM2_PCODE\",\"year\",\"month\",\"mean_EVI\"]].dropna(subset=[\"mean_EVI\"]),\n",
    "        \"mean_EVI\",\n",
    "        evi_s, evi_e,\n",
    "        EVI_DIR / f\"{adm2}_seasonal_overlay_evi.png\"\n",
    "    )\n",
    "\n",
    "print(\"Done. Saved updated overlays to:\")\n",
    "print(\" -\", NDVI_DIR)\n",
    "print(\" -\", EVI_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c6a81-9b2c-462a-8469-c93438547bec",
   "metadata": {},
   "source": [
    "### Output 'timeseries_ndvi_estharvest'/'timeseries_evi_estharvest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd178f80-e2e8-4504-8c9c-9b1d49e12b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time series with harvest shading: 100%|████████████████████████████████████████████████| 64/64 [00:44<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved time-series plots to:\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\timeseries_ndvi_estharvest\n",
      " - C:\\temp\\timor_leste\\ndvi_evi_outputs\\plots\\timeseries_evi_estharvest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Non-overlaid monthly time series with per-year harvest shading\n",
    "# ======================================================\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, MonthLocator, YearLocator\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Paths ----------\n",
    "if 'OUTPUT_DIR' not in globals():\n",
    "    OUTPUT_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi_outputs\")\n",
    "if 'PLOTS_DIR' not in globals():\n",
    "    PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NDVI_TS_DIR = PLOTS_DIR / \"timeseries_ndvi_estharvest\"\n",
    "EVI_TS_DIR  = PLOTS_DIR / \"timeseries_evi_estharvest\"\n",
    "NDVI_TS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EVI_TS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Monthly CSV location if `data` is missing\n",
    "if 'INPUT_DIR' in globals():\n",
    "    MONTHLY_DIR = Path(INPUT_DIR)\n",
    "else:\n",
    "    MONTHLY_DIR = Path(r\"C:\\temp\\timor_leste\\ndvi_evi\")\n",
    "\n",
    "HARVEST_CSV = OUTPUT_DIR / \"estimated_harvest_windows.csv\"\n",
    "if not HARVEST_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Missing {HARVEST_CSV}. Run the harvest-estimation cell first.\")\n",
    "harvest_df = pd.read_csv(HARVEST_CSV)\n",
    "\n",
    "# ---------- Load monthly data if needed ----------\n",
    "def _read_one_csv(fp: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'date' column in {fp}\")\n",
    "    df[\"date\"]  = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"]  = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    # ADM2 from filename if absent\n",
    "    adm2_guess = Path(fp).name.split(\"_\")[0]\n",
    "    if \"ADM2_PCODE\" not in df.columns:\n",
    "        df[\"ADM2_PCODE\"] = adm2_guess\n",
    "    else:\n",
    "        df[\"ADM2_PCODE\"] = df[\"ADM2_PCODE\"].fillna(adm2_guess)\n",
    "    # Coerce useful numeric fields\n",
    "    for col in [\"mean_NDVI\",\"mean_EVI\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _load_monthly_if_needed():\n",
    "    if 'data' in globals():\n",
    "        need = {\"ADM2_PCODE\",\"date\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"}\n",
    "        if isinstance(data, pd.DataFrame) and need.issubset(data.columns):\n",
    "            return data\n",
    "    files = glob.glob(str(MONTHLY_DIR / \"*.csv\"))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No monthly CSVs found in {MONTHLY_DIR}\")\n",
    "    frames = []\n",
    "    for fp in tqdm(files, desc=\"Loading monthly CSVs\"):\n",
    "        try:\n",
    "            frames.append(_read_one_csv(fp))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fp}: {e}\")\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No valid monthly CSVs loaded.\")\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "data = _load_monthly_if_needed()\n",
    "\n",
    "# Safety check\n",
    "need_cols = {\"ADM2_PCODE\",\"date\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"}\n",
    "missing = need_cols - set(data.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Monthly data missing columns: {missing}.\")\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "MONTH_NAMES = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "\n",
    "def _eom(year: int, month: int) -> datetime:\n",
    "    \"\"\"End-of-month date.\"\"\"\n",
    "    day = calendar.monthrange(year, month)[1]\n",
    "    return datetime(year, month, day)\n",
    "\n",
    "def _shades_for_year(y: int, start_m: int, end_m: int):\n",
    "    \"\"\"\n",
    "    Return list of (start_date, end_date) spans within calendar year y\n",
    "    to shade, given a start/end month (handles wrap).\n",
    "    \"\"\"\n",
    "    if pd.isna(start_m) or pd.isna(end_m):\n",
    "        return []\n",
    "    start_m = int(start_m); end_m = int(end_m)\n",
    "    spans = []\n",
    "    if 1 <= start_m <= 12 and 1 <= end_m <= 12:\n",
    "        if start_m <= end_m:\n",
    "            spans.append((datetime(y, start_m, 1), _eom(y, end_m)))\n",
    "        else:\n",
    "            # wrap: shade Jan..end_m and start_m..Dec inside the SAME calendar year\n",
    "            spans.append((datetime(y, 1, 1), _eom(y, end_m)))\n",
    "            spans.append((datetime(y, start_m, 1), datetime(y, 12, 31)))\n",
    "    return spans\n",
    "\n",
    "def _plot_timeseries_with_shading(df_adm2: pd.DataFrame,\n",
    "                                  value_col: str,\n",
    "                                  start_m: int, end_m: int,\n",
    "                                  out_path: Path):\n",
    "    dfp = df_adm2.sort_values(\"date\")\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dfp[\"date\"], dfp[value_col], marker=\"o\", linewidth=1.5, label=value_col)\n",
    "\n",
    "    # Per-year shading using estimated window months\n",
    "    for y in sorted(dfp[\"year\"].unique()):\n",
    "        for d0, d1 in _shades_for_year(y, start_m, end_m):\n",
    "            # limit to plotting range\n",
    "            left  = max(d0, dfp[\"date\"].min().to_pydatetime())\n",
    "            right = min(d1, dfp[\"date\"].max().to_pydatetime())\n",
    "            if left <= right:\n",
    "                ax.axvspan(left, right, alpha=0.12)\n",
    "\n",
    "    # Cosmetics\n",
    "    ax.set_ylim(0, 1)  # consistent scale\n",
    "    ax.set_ylabel(value_col)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    adm2 = str(dfp[\"ADM2_PCODE\"].iloc[0])\n",
    "    if not (pd.isna(start_m) or pd.isna(end_m)):\n",
    "        title_h = f\" (est. harvest {MONTH_NAMES[start_m-1]}–{MONTH_NAMES[end_m-1]})\"\n",
    "    else:\n",
    "        title_h = \" (no harvest estimate)\"\n",
    "    ax.set_title(f\"{adm2} — Monthly time series {title_h}\")\n",
    "\n",
    "    # Ticks/formatters\n",
    "    ax.xaxis.set_major_locator(YearLocator())\n",
    "    ax.xaxis.set_minor_locator(MonthLocator(bymonth=[1,4,7,10]))\n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "    ax.grid(True, axis=\"y\", alpha=0.2)\n",
    "    ax.legend(loc=\"upper right\", fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- Build maps for quick lookup ----------\n",
    "hw = harvest_df.set_index(\"ADM2_PCODE\").to_dict(orient=\"index\")\n",
    "\n",
    "# ---------- Generate plots ----------\n",
    "adm2_list = sorted(data[\"ADM2_PCODE\"].dropna().unique().tolist())\n",
    "\n",
    "for adm2 in tqdm(adm2_list, desc=\"Time series with harvest shading\"):\n",
    "    sub = data.loc[data[\"ADM2_PCODE\"] == adm2, [\"ADM2_PCODE\",\"date\",\"year\",\"month\",\"mean_NDVI\",\"mean_EVI\"]].dropna(subset=[\"date\"]).copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    # Ensure datetime dtype\n",
    "    sub[\"date\"] = pd.to_datetime(sub[\"date\"])\n",
    "\n",
    "    # NDVI window\n",
    "    ndvi_s = hw.get(adm2, {}).get(\"ndvi_start_month\", np.nan)\n",
    "    ndvi_e = hw.get(adm2, {}).get(\"ndvi_end_month\",   np.nan)\n",
    "    _plot_timeseries_with_shading(sub[[\"ADM2_PCODE\",\"date\",\"year\",\"mean_NDVI\"]].dropna(subset=[\"mean_NDVI\"]),\n",
    "                                  \"mean_NDVI\", ndvi_s, ndvi_e,\n",
    "                                  NDVI_TS_DIR / f\"{adm2}_timeseries_ndvi.png\")\n",
    "\n",
    "    # EVI window\n",
    "    evi_s  = hw.get(adm2, {}).get(\"evi_start_month\",  np.nan)\n",
    "    evi_e  = hw.get(adm2, {}).get(\"evi_end_month\",    np.nan)\n",
    "    _plot_timeseries_with_shading(sub[[\"ADM2_PCODE\",\"date\",\"year\",\"mean_EVI\"]].dropna(subset=[\"mean_EVI\"]),\n",
    "                                  \"mean_EVI\",  evi_s, evi_e,\n",
    "                                  EVI_TS_DIR  / f\"{adm2}_timeseries_evi.png\")\n",
    "\n",
    "print(\"Saved time-series plots to:\")\n",
    "print(\" -\", NDVI_TS_DIR)\n",
    "print(\" -\", EVI_TS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
