{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo5kwO9nl2-m"
   },
   "source": [
    "**MODIS NDVI value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Authenticate (only needed once per session or first-time setup)\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the Earth Engine client\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JQ1pokPvlJjA"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# Load ADM2 boundary for Timor-Leste\n",
    "adm2 = ee.FeatureCollection('projects/ee-spenson/assets/food-security-timor-leste/tls_admn_ad2_py_s2_unocha_pp')\n",
    "\n",
    "# Load MODIS dataset for the specified date range\n",
    "modis = ee.ImageCollection(\"MODIS/006/MOD09GA\") \\\n",
    "    .filterDate('2002-01-01', '2002-12-31') \\\n",
    "    .filterBounds(adm2)\n",
    "\n",
    "# Load cropland mask (USGS GFSAD 1km dataset)\n",
    "crop_mask = ee.Image(\"USGS/GFSAD1000_V1\")\n",
    "\n",
    "# Cloud masking function\n",
    "def mask_clouds(image):\n",
    "    cloud_mask = image.select('state_1km').bitwiseAnd(3).eq(0)\n",
    "    return image.updateMask(cloud_mask)\n",
    "\n",
    "# NDVI calculation function\n",
    "def calculate_ndvi(image):\n",
    "    ndvi = image.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).rename('NDVI')\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "# Cropland masking function\n",
    "def mask_cropland(image):\n",
    "    return image.updateMask(crop_mask)\n",
    "\n",
    "# Add date metadata\n",
    "def add_date_properties(image):\n",
    "    date = ee.Date(image.get('system:time_start'))\n",
    "    year = date.get('year')\n",
    "    month = date.get('month')\n",
    "    return image.set({'year': year, 'month': month})\n",
    "\n",
    "# Add cloud percentage as a property\n",
    "def add_cloud_percentage(image):\n",
    "    cloud_pixels = image.select('state_1km').bitwiseAnd(3).neq(0).reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=adm2.geometry(),\n",
    "        scale=1000,\n",
    "        maxPixels=1e13\n",
    "    ).get('state_1km')\n",
    "    \n",
    "    total_pixels = image.select('state_1km').reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        geometry=adm2.geometry(),\n",
    "        scale=1000,\n",
    "        maxPixels=1e13\n",
    "    ).get('state_1km')\n",
    "    \n",
    "    cloud_percentage = ee.Number(cloud_pixels).divide(ee.Number(total_pixels)).multiply(100)\n",
    "    return image.set('cloud_percentage', cloud_percentage)\n",
    "\n",
    "# Process image collection\n",
    "modis_ndvi = modis.map(mask_clouds).map(calculate_ndvi).map(mask_cropland)\n",
    "modis_ndvi = modis_ndvi.map(add_date_properties).map(add_cloud_percentage)\n",
    "\n",
    "# Filter for <10% cloud cover\n",
    "modis_filtered = modis_ndvi.filter(ee.Filter.lt('cloud_percentage', 10))\n",
    "\n",
    "# Per-month, per-ADM2 NDVI statistics\n",
    "def process_year_month(year, month, image_collection, admin_boundaries):\n",
    "    monthly_images = image_collection \\\n",
    "        .filter(ee.Filter.eq('year', year)) \\\n",
    "        .filter(ee.Filter.eq('month', month))\n",
    "\n",
    "    def assign_invalid():\n",
    "        return admin_boundaries.map(lambda feature: feature.set({\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'ADM2_PT': feature.get('ADM2_PT'),\n",
    "            'ADM2_PCODE': feature.get('ADM2_PCODE'),\n",
    "            'Shape_Area': feature.get('Shape_Area'),\n",
    "            'NDVI_mean': -9999,\n",
    "            'NDVI_median': -9999\n",
    "        }))\n",
    "\n",
    "    if monthly_images.size().getInfo() == 0:\n",
    "        return assign_invalid()\n",
    "    else:\n",
    "        mean_ndvi = monthly_images.select('NDVI').mean()\n",
    "        median_ndvi = monthly_images.select('NDVI').median()\n",
    "\n",
    "        mean_reduced = mean_ndvi.reduceRegions(\n",
    "            collection=admin_boundaries,\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            scale=1000\n",
    "        )\n",
    "\n",
    "        median_reduced = median_ndvi.reduceRegions(\n",
    "            collection=admin_boundaries,\n",
    "            reducer=ee.Reducer.median(),\n",
    "            scale=1000\n",
    "        )\n",
    "\n",
    "        return mean_reduced.map(lambda f: f.set({\n",
    "            'NDVI_median': median_reduced.filter(\n",
    "                ee.Filter.equals('ADM2_PCODE', f.get('ADM2_PCODE'))\n",
    "            ).first().get('median'),\n",
    "            'year': year,\n",
    "            'month': month\n",
    "        }))\n",
    "\n",
    "# Loop through year/month and reduce\n",
    "def reduce_to_monthly_means(image_collection, admin_boundaries):\n",
    "    months = ee.List.sequence(1, 12)\n",
    "    years = ee.List.sequence(2002, 2002)\n",
    "\n",
    "    results = []\n",
    "    for year in years.getInfo():\n",
    "        for month in months.getInfo():\n",
    "            results.append(process_year_month(year, month, image_collection, admin_boundaries))\n",
    "\n",
    "    return ee.FeatureCollection(results).flatten()\n",
    "\n",
    "# Generate final NDVI statistics per ADM2\n",
    "monthly_ndvi = reduce_to_monthly_means(modis_filtered, adm2)\n",
    "\n",
    "# Clean and export\n",
    "monthly_ndvi_cleaned = monthly_ndvi.map(lambda f: f.set({\n",
    "    'NDVI_mean': f.get('mean'),\n",
    "    'NDVI_median': f.get('NDVI_median'),\n",
    "    'ADM2_PT': f.get('ADM2_PT'),\n",
    "    'ADM2_PCODE': f.get('ADM2_PCODE'),\n",
    "    'year': f.get('year'),\n",
    "    'month': f.get('month'),\n",
    "    'Shape_Area': f.get('Shape_Area')\n",
    "}))\n",
    "\n",
    "# Export to Google Drive\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=monthly_ndvi_cleaned,\n",
    "    description='TimorLeste_MODIS_NDVI_2002',\n",
    "    folder='GEE_timor_leste_MODIS',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "task.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXqtM0A6lKuk"
   },
   "source": [
    "**Fusion NDVI value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4lS2SH_3lLet"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m landsat_combined_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m total_weight\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Add a new column to the merged dataset for fused NDVI\u001b[39;00m\n\u001b[0;32m     18\u001b[0m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused_NDVI\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 19\u001b[0m     modis_combined_weight \u001b[38;5;241m*\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODIS_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     20\u001b[0m     landsat_combined_weight \u001b[38;5;241m*\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLANDSAT_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Define spatial and temporal weights\n",
    "modis_spatial_weight = 1 / 250  # MODIS spatial resolution (250m)\n",
    "landsat_spatial_weight = 1 / 30  # Landsat spatial resolution (30m)\n",
    "\n",
    "modis_temporal_weight = 1 / 8  # MODIS temporal resolution (8-day composites)\n",
    "landsat_temporal_weight = 1 / 16  # Landsat temporal resolution (16-day intervals)\n",
    "\n",
    "# Combine spatial and temporal weights\n",
    "modis_combined_weight = modis_spatial_weight * modis_temporal_weight\n",
    "landsat_combined_weight = landsat_spatial_weight * landsat_temporal_weight\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "total_weight = modis_combined_weight + landsat_combined_weight\n",
    "modis_combined_weight /= total_weight\n",
    "landsat_combined_weight /= total_weight\n",
    "\n",
    "# Add a new column to the merged dataset for fused NDVI\n",
    "merged_data['fused_NDVI'] = (\n",
    "    modis_combined_weight * merged_data['MODIS_mean'] +\n",
    "    landsat_combined_weight * merged_data['LANDSAT_mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJx0zWDUlPMl"
   },
   "source": [
    "**Fixed Fusion NDVI value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6W__QLLulTKO"
   },
   "outputs": [],
   "source": [
    "# Define fixed weights\n",
    "modis_fixed_weight = 0.3  # Adjust this to 0.5, 0.7, etc.\n",
    "landsat_fixed_weight = 0.7  # Adjust this to 0.5, 0.3, etc.\n",
    "\n",
    "# Ensure weights sum to 1 (optional step to verify)\n",
    "assert modis_fixed_weight + landsat_fixed_weight == 1, \"Weights must sum to 1.\"\n",
    "\n",
    "# Calculate fused NDVI using fixed weights\n",
    "merged_data['fused_NDVI_M3L7'] = (\n",
    "    modis_fixed_weight * merged_data['MODIS_mean'] +\n",
    "    landsat_fixed_weight * merged_data['LANDSAT_mean']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
