{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MODIS NDVI value**"
      ],
      "metadata": {
        "id": "Xo5kwO9nl2-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ1pokPvlJjA"
      },
      "outputs": [],
      "source": [
        "# Load MODIS dataset for the specified date range\n",
        "modis = ee.ImageCollection(\"MODIS/006/MOD09GA\") \\\n",
        "    .filterDate('2002-01-01', '2002-12-31') \\\n",
        "    .filterBounds(adm2)\n",
        "\n",
        "# Load cropland mask (USGS GFSAD 1km dataset)\n",
        "crop_mask = ee.Image(\"USGS/GFSAD1000_V1\")\n",
        "\n",
        "# Function to mask clouds\n",
        "def mask_clouds(image):\n",
        "    cloud_mask = image.select('state_1km').bitwiseAnd(3).eq(0)\n",
        "    return image.updateMask(cloud_mask)\n",
        "\n",
        "# Function to calculate NDVI\n",
        "def calculate_ndvi(image):\n",
        "    ndvi = image.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).rename('NDVI')\n",
        "    return image.addBands(ndvi)\n",
        "\n",
        "# Apply cloud masking and calculate NDVI\n",
        "modis_ndvi = modis.map(mask_clouds).map(calculate_ndvi)\n",
        "\n",
        "# Mask cropland areas\n",
        "def mask_cropland(image):\n",
        "    return image.updateMask(crop_mask)\n",
        "\n",
        "modis_ndvi_cropland = modis_ndvi.map(mask_cropland)\n",
        "\n",
        "# Add year and month metadata to each image\n",
        "def add_date_properties(image):\n",
        "    date = ee.Date(image.get('system:time_start'))\n",
        "    year = date.get('year')\n",
        "    month = date.get('month')\n",
        "    return image.set({'year': year, 'month': month})\n",
        "\n",
        "modis_ndvi_cropland = modis_ndvi_cropland.map(add_date_properties)\n",
        "\n",
        "# Filter for images with less than 10% cloud cover\n",
        "def add_cloud_percentage(image):\n",
        "    cloud_pixels = image.select('state_1km').bitwiseAnd(3).neq(0).reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=adm2.geometry(),\n",
        "        scale=1000,\n",
        "        maxPixels=1e13\n",
        "    ).get('state_1km')\n",
        "    total_pixels = image.select('state_1km').reduceRegion(\n",
        "        reducer=ee.Reducer.count(),\n",
        "        geometry=adm2.geometry(),\n",
        "        scale=1000,\n",
        "        maxPixels=1e13\n",
        "    ).get('state_1km')\n",
        "    cloud_percentage = ee.Number(cloud_pixels).divide(ee.Number(total_pixels)).multiply(100)\n",
        "    return image.set('cloud_percentage', cloud_percentage)\n",
        "\n",
        "modis_ndvi_cropland = modis_ndvi_cropland.map(add_cloud_percentage)\n",
        "modis_filtered = modis_ndvi_cropland.filter(ee.Filter.lt('cloud_percentage', 10))\n",
        "\n",
        "\n",
        "# Group NDVI by ADM2, year, and month\n",
        "def process_year_month(year, month, image_collection, admin_boundaries):\n",
        "    # Filter by year and month\n",
        "    monthly_images = image_collection \\\n",
        "        .filter(ee.Filter.eq('year', year)) \\\n",
        "        .filter(ee.Filter.eq('month', month))\n",
        "\n",
        "    # If there are no valid images, assign -9999 for the mean and median NDVI\n",
        "    def assign_invalid():\n",
        "        return admin_boundaries.map(lambda feature: feature.set({\n",
        "            'year': year,\n",
        "            'month': month,\n",
        "            'ADM2_PT': feature.get('ADM2_PT'),\n",
        "            'ADM2_PCODE': feature.get('ADM2_PCODE'),\n",
        "            'Shape_Area': feature.get('Shape_Area'),\n",
        "            'NDVI_mean': -9999,   # Placeholder for mean NDVI\n",
        "            'NDVI_median': -9999  # Placeholder for median NDVI\n",
        "        }))\n",
        "\n",
        "    # If valid images exist, calculate the mean and median NDVI\n",
        "    if monthly_images.size().getInfo() == 0:\n",
        "        return assign_invalid()\n",
        "    else:\n",
        "        # Calculate mean NDVI\n",
        "        mean_ndvi = monthly_images.select('NDVI').mean()\n",
        "        # Calculate median NDVI\n",
        "        median_ndvi = monthly_images.select('NDVI').median()\n",
        "\n",
        "        # Reduce the mean and median over regions\n",
        "        mean_reduced = mean_ndvi.reduceRegions(\n",
        "            collection=admin_boundaries,\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            scale=1000\n",
        "        )\n",
        "        median_reduced = median_ndvi.reduceRegions(\n",
        "            collection=admin_boundaries,\n",
        "            reducer=ee.Reducer.median(),\n",
        "            scale=1000\n",
        "        )\n",
        "\n",
        "        # Combine the results into a single FeatureCollection\n",
        "        return mean_reduced.map(lambda f: f.set({\n",
        "            'NDVI_median': median_reduced.filter(\n",
        "                ee.Filter.equals('ADM2_PCODE', f.get('ADM2_PCODE'))\n",
        "            ).first().get('median'),\n",
        "            'year': year,\n",
        "            'month': month\n",
        "        }))\n",
        "\n",
        "def reduce_to_monthly_means(image_collection, admin_boundaries):\n",
        "    months = ee.List.sequence(1, 12)  # Months 1 to 12\n",
        "    years = ee.List.sequence(2002, 2002)  # Year 2002 only\n",
        "\n",
        "    results = []\n",
        "    for year in years.getInfo():\n",
        "        for month in months.getInfo():\n",
        "            results.append(process_year_month(year, month, image_collection, admin_boundaries))\n",
        "\n",
        "    # Flatten the list of FeatureCollections into a single FeatureCollection\n",
        "    return ee.FeatureCollection(results).flatten()\n",
        "\n",
        "# Reduce NDVI data by ADM2 boundaries\n",
        "monthly_ndvi = reduce_to_monthly_means(modis_filtered, adm2)\n",
        "\n",
        "# Select only the requested fields\n",
        "monthly_ndvi_cleaned = monthly_ndvi.map(lambda f: f.set({\n",
        "    'NDVI_mean': f.get('mean'),\n",
        "    'NDVI_median': f.get('NDVI_median'),\n",
        "    'ADM2_PT': f.get('ADM2_PT'),\n",
        "    'ADM2_PCODE': f.get('ADM2_PCODE'),\n",
        "    'year': f.get('year'),\n",
        "    'month': f.get('month'),\n",
        "    'Shape_Area': f.get('Shape_Area')\n",
        "}))\n",
        "\n",
        "# Export results to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=monthly_ndvi_cleaned,\n",
        "    description='V1_Mozambique_mean_medi_2002',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fusion NDVI value**"
      ],
      "metadata": {
        "id": "XXqtM0A6lKuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define spatial and temporal weights\n",
        "modis_spatial_weight = 1 / 250  # MODIS spatial resolution (250m)\n",
        "landsat_spatial_weight = 1 / 30  # Landsat spatial resolution (30m)\n",
        "\n",
        "modis_temporal_weight = 1 / 8  # MODIS temporal resolution (8-day composites)\n",
        "landsat_temporal_weight = 1 / 16  # Landsat temporal resolution (16-day intervals)\n",
        "\n",
        "# Combine spatial and temporal weights\n",
        "modis_combined_weight = modis_spatial_weight * modis_temporal_weight\n",
        "landsat_combined_weight = landsat_spatial_weight * landsat_temporal_weight\n",
        "\n",
        "# Normalize weights to sum to 1\n",
        "total_weight = modis_combined_weight + landsat_combined_weight\n",
        "modis_combined_weight /= total_weight\n",
        "landsat_combined_weight /= total_weight\n",
        "\n",
        "# Add a new column to the merged dataset for fused NDVI\n",
        "merged_data['fused_NDVI'] = (\n",
        "    modis_combined_weight * merged_data['MODIS_mean'] +\n",
        "    landsat_combined_weight * merged_data['LANDSAT_mean']\n",
        ")"
      ],
      "metadata": {
        "id": "4lS2SH_3lLet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fixed Fusion NDVI value**"
      ],
      "metadata": {
        "id": "lJx0zWDUlPMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fixed weights\n",
        "modis_fixed_weight = 0.3  # Adjust this to 0.5, 0.7, etc.\n",
        "landsat_fixed_weight = 0.7  # Adjust this to 0.5, 0.3, etc.\n",
        "\n",
        "# Ensure weights sum to 1 (optional step to verify)\n",
        "assert modis_fixed_weight + landsat_fixed_weight == 1, \"Weights must sum to 1.\"\n",
        "\n",
        "# Calculate fused NDVI using fixed weights\n",
        "merged_data['fused_NDVI_M3L7'] = (\n",
        "    modis_fixed_weight * merged_data['MODIS_mean'] +\n",
        "    landsat_fixed_weight * merged_data['LANDSAT_mean']\n",
        ")"
      ],
      "metadata": {
        "id": "6W__QLLulTKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}